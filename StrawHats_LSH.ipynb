{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StrawHats LSH.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oG9wh4kCfsz5",
        "outputId": "d6b3f05c-15b1-4ca7-dc1d-e1704bd31584"
      },
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "from spacy import displacy\n",
        "from spacy.matcher import Matcher\n",
        "from spacy.tokens import Span\n",
        "from spacy.tokens import Doc\n",
        "from spacy.util import minibatch, compounding\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "spacy.require_gpu()\n",
        "#nlp  = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "196eOiYvc6Bi"
      },
      "source": [
        "Hear we are using spacy en_core_web_lg model which is spacy's full version for english language, we are using this model with google col;ab GPU's to get better and fast results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbiW5g9xc5-B"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfHK7NZkjvhj",
        "outputId": "441e0104-e3c8-4eab-e4e4-28242f1bcd45"
      },
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (54.2.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.1)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp37-none-any.whl size=829180944 sha256=c86f56477a3299ab9f33afad06393ddcbc4e0a4868eace910a8d2e3d2b44d9fa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-anmgjtzl/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOUB3CrYjqZY"
      },
      "source": [
        "\n",
        "#laoding the model \n",
        "nlp  = spacy.load('en_core_web_lg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo34E94jf6lM",
        "outputId": "395bb64c-25cb-40a7-ad23-7a048ae41235"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "yZrdUUOHf7Zy",
        "outputId": "a5977c84-e1ed-45bc-f514-950ce723b7aa"
      },
      "source": [
        "data = pd.read_csv('/content/gdrive/MyDrive/StrawHats projects/News scraping.csv')\n",
        "data = data.drop(['Language','Date','Time','Source Link','Author/Publisher'], axis=1)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Sub_Category</th>\n",
              "      <th>Title</th>\n",
              "      <th>Synopsis</th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>BWF World Tour Finals: Fighting PV Sindhu lose...</td>\n",
              "      <td>This was PV Sindhu's 16th defeat to Tai Tzu Yi...</td>\n",
              "      <td>World champion shuttler P V Sindhu went down f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>World Tour Finals Preview: PV Sindhu, recharge...</td>\n",
              "      <td>With the Indian having played more matches tha...</td>\n",
              "      <td>Carolina Marin (50 total) played 24 tournament...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>Satwiksairaj’s offence gets neutralised by sav...</td>\n",
              "      <td>Satwiksairaj Rankireddy uses big smash to kill...</td>\n",
              "      <td>One would have to be blind to not figure that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>Dream run of Indian doubles pairs end with sem...</td>\n",
              "      <td>Up against the world number three Thai pair, S...</td>\n",
              "      <td>The Indian mixed doubles pair of Satwiksairaj ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>Satwik-Chirag’s impressive run ends with semif...</td>\n",
              "      <td>The Indian pair had participated in Super 1000...</td>\n",
              "      <td>Tokyo Olympics medal contender Satwiksairaj Ra...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Category  ...                                               News\n",
              "0   Sports  ...  World champion shuttler P V Sindhu went down f...\n",
              "1   Sports  ...  Carolina Marin (50 total) played 24 tournament...\n",
              "2   Sports  ...  One would have to be blind to not figure that ...\n",
              "3   Sports  ...  The Indian mixed doubles pair of Satwiksairaj ...\n",
              "4   Sports  ...  Tokyo Olympics medal contender Satwiksairaj Ra...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKt-6W68gAo7"
      },
      "source": [
        "#NER "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WqMy_2wB6NA"
      },
      "source": [
        "We are using the Named entity recognition(NER) technique to process and analyse all the web scraped data. \\\\\n",
        "\n",
        "**Named entity recognition(NER):-** NER represents the technique of chunking, extraction or identification of the particular entities in the data. It helps to identify and categorize critical information in the text. An entity can be any word or series of words that consistently refers to the same thing. Each newly detected entity is classified into a predetermined category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OImCHXd3MiTK"
      },
      "source": [
        "import spacy\n",
        "from wordcloud import STOPWORDS, WordCloud\n",
        "from spacy.util import minibatch,compounding\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IAtT2lQdYEO"
      },
      "source": [
        "These two codes will extract entities from the news as tags and we will use those tags for training our LSH modelfor accurate results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVH5lK3igGGw"
      },
      "source": [
        "def NER_tags(in_news):\n",
        "  tag = []\n",
        "\n",
        "  for text in in_news:\n",
        "    text = str(text)\n",
        "    doc = nlp(text)\n",
        "    for ent in doc.ents:\n",
        "      if ent.label_ == 'CARDINAL':\n",
        "        pass\n",
        "      elif ent.label_ == 'ORDINAL':\n",
        "        pass\n",
        "      elif ent.label_ == 'DATE':\n",
        "        pass\n",
        "      elif ent.label_ == 'TIME':\n",
        "        pass\n",
        "      else:\n",
        "        tag.append(ent.text)\n",
        "        tag_in = ' '.join(tag)\n",
        "  return tag_in\n",
        "\n",
        "def hash_tags(in_news):\n",
        "    tag = []\n",
        "\n",
        "  \n",
        "    text = str(in_news)\n",
        "    doc = nlp(text)\n",
        "    for ent in doc.ents:\n",
        "      if ent.label_ == 'CARDINAL':\n",
        "        pass\n",
        "      elif ent.label_ == 'ORDINAL':\n",
        "        pass\n",
        "      elif ent.label_ == 'DATE':\n",
        "        pass\n",
        "      elif ent.label_ == 'TIME':\n",
        "        pass\n",
        "      else:\n",
        "        tag.append(ent.text)\n",
        "        tag_in = ' '.join(tag)\n",
        "    return tag_in \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjo-TtLDd_HK"
      },
      "source": [
        "Hear we are using above functions to extract tags from the news contents so we are not going to miss any importent detail or tag related to news, and these NER tags are extremly useful in our NER+LSH algorithm which is giving us very good results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZSbTyGakU-c"
      },
      "source": [
        "data['tags'] = data['News'].apply(lambda x: hash_tags(x))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "5CDvAvAhpu-L",
        "outputId": "6bb5614d-ce39-4344-92ed-9f4864a9931f"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Sub_Category</th>\n",
              "      <th>Title</th>\n",
              "      <th>Synopsis</th>\n",
              "      <th>News</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>BWF World Tour Finals: Fighting PV Sindhu lose...</td>\n",
              "      <td>This was PV Sindhu's 16th defeat to Tai Tzu Yi...</td>\n",
              "      <td>World champion shuttler P V Sindhu went down f...</td>\n",
              "      <td>Tai Tzu Ying Taiwan $1.5 million HSBC BWF Worl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>World Tour Finals Preview: PV Sindhu, recharge...</td>\n",
              "      <td>With the Indian having played more matches tha...</td>\n",
              "      <td>Carolina Marin (50 total) played 24 tournament...</td>\n",
              "      <td>Carolina Marin PV Sindhu Indian Marin Sindhu O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>Satwiksairaj’s offence gets neutralised by sav...</td>\n",
              "      <td>Satwiksairaj Rankireddy uses big smash to kill...</td>\n",
              "      <td>One would have to be blind to not figure that ...</td>\n",
              "      <td>Satwiksairaj Rankireddy Neutralising Malaysian...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>Dream run of Indian doubles pairs end with sem...</td>\n",
              "      <td>Up against the world number three Thai pair, S...</td>\n",
              "      <td>The Indian mixed doubles pair of Satwiksairaj ...</td>\n",
              "      <td>Indian Satwiksairaj Rankireddy Ashwini Ponnapp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>Satwik-Chirag’s impressive run ends with semif...</td>\n",
              "      <td>The Indian pair had participated in Super 1000...</td>\n",
              "      <td>Tokyo Olympics medal contender Satwiksairaj Ra...</td>\n",
              "      <td>Tokyo Olympics Satwiksairaj Rankireddy Chirag ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5918</th>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Box-office-collection</td>\n",
              "      <td>Kesari box office collection Day 8: Akshay Kum...</td>\n",
              "      <td>Kesari box office collection Day 8: Akshay Kum...</td>\n",
              "      <td>Kesari, starring Akshay Kumar in the lead role...</td>\n",
              "      <td>Kesari Akshay Kumar Rs 105.86 crore Taran Adar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5919</th>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Box-office-collection</td>\n",
              "      <td>Junglee box office prediction: Vidyut Jammwal ...</td>\n",
              "      <td>Junglee box office prediction: Junglee will ha...</td>\n",
              "      <td>Vidyut Jammwal’s Junglee has caught the fancy ...</td>\n",
              "      <td>Vidyut Jammwal’s Junglee Kesari Notebook Chuck...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5920</th>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Box-office-collection</td>\n",
              "      <td>Luka Chuppi box office collection Day 26: Kart...</td>\n",
              "      <td>Luka Chuppi box office collection Day 26: Krit...</td>\n",
              "      <td>Kriti Sanon and Kartik Aaryan’s film Luka Chup...</td>\n",
              "      <td>Kriti Sanon Kartik Aaryan Luka Chuppi Rs 43 la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5921</th>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Box-office-collection</td>\n",
              "      <td>Badla box office collection day 20: Going gets...</td>\n",
              "      <td>Badla box office collection day 20: Taapsee Pa...</td>\n",
              "      <td>After more than 2 weeks, Taapsee Pannu’s film ...</td>\n",
              "      <td>Taapsee Pannu’s Badla Badla Rs 1 crore only Rs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5922</th>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Box-office-collection</td>\n",
              "      <td>Kesari box office collection Day 7: Akshay Kum...</td>\n",
              "      <td>Kesari box office collection Day 7: Akshay Kum...</td>\n",
              "      <td>Akshay Kumar starrer Kesari has become the fas...</td>\n",
              "      <td>Akshay Kumar starrer Kesari Rs 100 crore Gully...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5923 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Category  ...                                               tags\n",
              "0            Sports  ...  Tai Tzu Ying Taiwan $1.5 million HSBC BWF Worl...\n",
              "1            Sports  ...  Carolina Marin PV Sindhu Indian Marin Sindhu O...\n",
              "2            Sports  ...  Satwiksairaj Rankireddy Neutralising Malaysian...\n",
              "3            Sports  ...  Indian Satwiksairaj Rankireddy Ashwini Ponnapp...\n",
              "4            Sports  ...  Tokyo Olympics Satwiksairaj Rankireddy Chirag ...\n",
              "...             ...  ...                                                ...\n",
              "5918  Entertainment  ...  Kesari Akshay Kumar Rs 105.86 crore Taran Adar...\n",
              "5919  Entertainment  ...  Vidyut Jammwal’s Junglee Kesari Notebook Chuck...\n",
              "5920  Entertainment  ...  Kriti Sanon Kartik Aaryan Luka Chuppi Rs 43 la...\n",
              "5921  Entertainment  ...  Taapsee Pannu’s Badla Badla Rs 1 crore only Rs...\n",
              "5922  Entertainment  ...  Akshay Kumar starrer Kesari Rs 100 crore Gully...\n",
              "\n",
              "[5923 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pYQ3C0VidPI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "28997aa2-6eaa-48aa-e6ba-880efb4ce355"
      },
      "source": [
        "tag =  NER_tags(data['Synopsis'][234:237])\n",
        "tag"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Satwik the World the Fuzhou China Open 2019 Indian Marcus Kevin the BWF World Tour Super Satwik -Chirag Marcus-Kevin Fuzhou Indian Marcus Fernaldi Gideon Kevin Sanjaya French Open'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AHoy5JykDvb7",
        "outputId": "74ca1f43-ff26-4efe-b55f-9accf49d3b2b"
      },
      "source": [
        "hash_tag = hash_tags(data['Synopsis'][234:237])\n",
        "ta = list(set(hash_tag))\n",
        "hash_tag"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Satwik-Chirag Indian Satwik-Chirag Marcus-Kevin Fuzhou'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKijIUv_f92a"
      },
      "source": [
        "#LSH\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTOZuofc_qG1"
      },
      "source": [
        "We are using the technique of Locality-sensitive hashing(LSH) to find out the most relevant news articles to recommend to a user. \\\\\n",
        "**Locality-sensitive hashing(LSH)**:- LSH is a model with the help of which we can sort out the similar input items into the same bucket. Here the number of buckets is small compared to the number of input items. So, we can sort out mostly similar items together in the same bucket and present them in hashtags. \\\\\n",
        "\n",
        "To understand the LSH technique mathematically, let us define a Hash family $H$. \\\\\n",
        "\n",
        "Now, $P[h(x) = h(y)]$ indicates the probability such that two points $h(x)$ and $h(y)$ in the Hash family H are equal. The Hash family $H$ is locality sensitive if, \\\\\n",
        "\n",
        "$P[h(x) = h(y)]$  is high if $x$ is close to $y$   , \\\\\n",
        "\n",
        "$P[h(x) = h(y)]$  is low if $x$ is away from $y$. \\\\\n",
        "\n",
        "The high probabilty indicates that the two points are likely to be included in the same bucket. \\\\\n",
        "\n",
        "The similarity between two points is calculated using the known method of Jaccard similarity. The Jaccard Similarity index is calculated as, \\\\\n",
        "\n",
        "$J(A,B) = \\frac{|A \\cap B|}{|A \\cup B |}$ \n",
        "\n",
        "Where, $J(A,B)$ is the Jaccard distance between two sets points A and B. \n",
        "\n",
        "Mathematically, we can write ,\n",
        "\n",
        "For a Given universe $U$ and similarity $s: U \\times U \\rightarrow [0,1]$ , There exists a probability distribution over some Hash family H such that \n",
        "\n",
        "$P[h(x) = h(y)] = s(x,y)$ \n",
        "\n",
        "whre $ h \\in H$ and $s(x,y) = s(y,x)$. \n",
        "\n",
        "And $s(x,y) = 1 \\rightarrow x=y $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qfgFaNQegFg"
      },
      "source": [
        "We are going to use data scatch library to make LSH model by usinfg MinHash forest you can see the details heaar  https://github.com/ekzhu/datasketch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAoWpOtBegCl"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_Sf0LT6gr8s",
        "outputId": "32f20d96-121c-416f-deee-fede7114988f"
      },
      "source": [
        "!pip install datasketch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datasketch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/35/3e39356d97dc67c4bddaddb51693c20a6eb61e535ce5be09d3755ba2b823/datasketch-1.5.3-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 29.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 40kB 24.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 23.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 25.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from datasketch) (1.19.5)\n",
            "Installing collected packages: datasketch\n",
            "Successfully installed datasketch-1.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRfa3DRSgr6N"
      },
      "source": [
        "import datasketch\n",
        "from datasketch import MinHash , MinHashLSH, MinHashLSHEnsemble, MinHashLSHForest\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "stop_words = STOP_WORDS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10VB8Ance4qH"
      },
      "source": [
        "Hear are all the text pre-processing that we are using in our algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IjHkMSngrSC"
      },
      "source": [
        "\n",
        "def clean_text(text ): \n",
        "    delete_dict = {sp_character: '' for sp_character in string.punctuation} \n",
        "    delete_dict[' '] = ' ' \n",
        "    table = str.maketrans(delete_dict)\n",
        "    text1 = text.translate(table)\n",
        "    #print('cleaned:'+text1)\n",
        "    textArr= text1.split()\n",
        "    text2 = ' '.join([w for w in textArr if ( not w.isdigit() and  ( not w.isdigit() and len(w)>3))]) \n",
        "    \n",
        "    return text2.lower()\n",
        "\n",
        "#Cleantext for News\n",
        "data['News'] = data['News'].apply(clean_text)\n",
        "#cleantext for synopsis\n",
        "data['Synopsis'] = data['Synopsis'].apply(clean_text)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMKrPoi7uDJX"
      },
      "source": [
        "#Lets remove the common words\n",
        "# Common word removal\n",
        "common_words = pd.Series(' '.join(data['News']).split()).value_counts()[:50]\n",
        "common_words = list(common_words.index)\n",
        "data['News'] = data['News'].apply(lambda x: \" \".join(x for x in x.split() if x not in common_words))\n",
        "#common wordes removel for synopsis\n",
        "common_words = pd.Series(' '.join(data['Synopsis']).split()).value_counts()[:50]\n",
        "common_words = list(common_words.index)\n",
        "data['Synopsis'] = data['Synopsis'].apply(lambda x: \" \".join(x for x in x.split() if x not in common_words))\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "# function to remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    textArr = text.split(' ')\n",
        "    rem_text = \" \".join([i for i in textArr if i not in stop_words])\n",
        "    return rem_text\n",
        "\n",
        "# remove stopwords from the News\n",
        "data['news_without_stop']=data['News'].apply(remove_stopwords)\n",
        "\n",
        "\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "\n",
        "def lemmatization(texts,allowed_postags=['NOUN', 'ADJ']): \n",
        "       output = []\n",
        "       for sent in texts:\n",
        "             doc = nlp(sent) \n",
        "             output.append([token.lemma_ for token in doc if token.pos_ in allowed_postags ])\n",
        "       return output\n",
        "\n",
        "text_list=data['news_without_stop'].tolist()\n",
        "print(text_list[1])\n",
        "tokenized_reviews = lemmatization(text_list)\n",
        "print(tokenized_reviews[1])\n",
        "\n",
        "dictionary = corpora.Dictionary(tokenized_reviews)\n",
        "doc_term_matrix = [dictionary.doc2bow(rev) for rev in tokenized_reviews]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brqSd6yFtccN"
      },
      "source": [
        "#Preprocess will split a string of text into individual tokens/shingles based on whitespace.\n",
        "def preprocess(text):\n",
        "    textArr = text.split(' ')\n",
        "    rem_text = \" \".join([i for i in textArr if i not in stop_words])\n",
        "    text = re.sub(r'[^\\w\\s]','',rem_text)\n",
        "    tokens = text.lower()\n",
        "    tokens = tokens.split()\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eaaeb6Imfu5y"
      },
      "source": [
        "Hear what the main LSH work is going on so what we are doing hear is we are using MinhashLSH forest to make our model based on NER tags that we have extracted eirlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg7pywH_trYh"
      },
      "source": [
        "#data['tokenized'] = data['Synopsis'].apply(preprocess)\n",
        "#Number of Permutations\n",
        "permutations = 128\n",
        "\n",
        "#Number of Recommendations to return\n",
        "num_recommendations = 1\n",
        "\n",
        "def get_forest(data, perms):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    minhash = []\n",
        "    \n",
        "    for text in data['tags']:\n",
        "        tokens = preprocess(text)\n",
        "        m = MinHash(num_perm=perms)\n",
        "        for s in tokens:\n",
        "            m.update(s.encode('utf8'))\n",
        "        minhash.append(m)\n",
        "        \n",
        "    forest = MinHashLSHForest(num_perm=perms)\n",
        "    \n",
        "    for i,m in enumerate(minhash):\n",
        "        forest.add(i,m)\n",
        "        \n",
        "    forest.index()\n",
        "    \n",
        "    print('It took %s seconds to build forest.' %(time.time()-start_time))\n",
        "    \n",
        "    return forest\n",
        "\n",
        "def predict(text, database, perms, num_results, forest):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    tokens = preprocess(text)\n",
        "    m = MinHash(num_perm=perms)\n",
        "    for s in tokens:\n",
        "        m.update(s.encode('utf8'))\n",
        "        \n",
        "    idx_array = np.array(forest.query(m, num_results))\n",
        "    if len(idx_array) == 0:\n",
        "        return None # if your query is empty, return none\n",
        "    \n",
        "    result = database.iloc[idx_array]['News']\n",
        "    ls_idx = idx_array.tolist()\n",
        "    \n",
        "    print('It took %s seconds to query forest.' %(time.time()-start_time))\n",
        "    \n",
        "    return ls_idx , result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "idlAdH2YrNAy",
        "outputId": "5fe9a141-7fe3-438b-99c7-447141d01df6"
      },
      "source": [
        " #index to data frame function\n",
        " def idx_to_df(idx, data):\n",
        "   c = (data.iloc[idx]).to_frame().T\n",
        "   return c\n",
        "idx_to_df(245 , data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Sub_Category</th>\n",
              "      <th>Title</th>\n",
              "      <th>Synopsis</th>\n",
              "      <th>News</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>Lakshya Sen beats China’s Weng Hong Yang to cl...</td>\n",
              "      <td>Lakshya Sen bagged his second successive BWF W...</td>\n",
              "      <td>India’s Lakshya Sen bagged his second successi...</td>\n",
              "      <td>India Lakshya Sen BWF World Tour Super 100 Chi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Category  ...                                               tags\n",
              "245   Sports  ...  India Lakshya Sen BWF World Tour Super 100 Chi...\n",
              "\n",
              "[1 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09qkDFYet75a",
        "outputId": "6b9fb746-c91e-4c2b-ff64-a24dbb31251a"
      },
      "source": [
        "\n",
        "forest = get_forest(data, permutations)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It took 11.715883731842041 seconds to build forest.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxhDsjxfgMdp"
      },
      "source": [
        "First test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9vTeEoCvdEj",
        "outputId": "7bd5d224-0b58-4830-d96b-e73b7c54997d"
      },
      "source": [
        "num_recommendations = 10\n",
        "Synopsis = tag # tag is defined above in NER section\n",
        "result = predict(Synopsis, data, permutations, num_recommendations, forest)[1]\n",
        "print('\\n Top Recommendation(s) is(are) \\n', result)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It took 0.013955116271972656 seconds to query forest.\n",
            "\n",
            " Top Recommendation(s) is(are) \n",
            " 258     French Open 2019 Live Streaming: Saina Nehwal,...\n",
            "2341    WWE superstar Nia Jax created history on Monda...\n",
            "261     Kuhoo Garg and Dhruv Rawat put up a brilliant ...\n",
            "296     China Open Badminton 2019 Live Score Streaming...\n",
            "297     China Open Badminton 2019 Schedule, Players Li...\n",
            "236     Satwik-Chirag vs Marcus-Kevin, Fuzhou China Op...\n",
            "273     Denmark Open Badminton 2019 Schedule, Players ...\n",
            "2323    WWE Elimination Chamber 2019: On the road to W...\n",
            "2295    WWE Fastlane 2019 in Cleveland, Ohio was the p...\n",
            "4863    David Lynch should ask Remedy Entertainment fo...\n",
            "Name: News, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aotEqtuZgcvs"
      },
      "source": [
        "So our model is working perfectly so lets make a recommander which will use user data to give recommandations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7ls0Vk15EkW"
      },
      "source": [
        "def recommander(News_in , num_reco):\n",
        "  results = pd.DataFrame(columns= ['Category', 'Sub_Category', 'Title',\n",
        "       'Synopsis', 'News'])\n",
        "  \n",
        "  num_recommendations =num_reco\n",
        "  permutations = 128\n",
        "  NER_tag = NER_tags(News_in)\n",
        "  result = list(predict(NER_tag, data, permutations, num_recommendations, forest))[0]\n",
        "  for idx in result:\n",
        "      c = idx_to_df(idx , data)\n",
        "      results = results.append(c)\n",
        "  return results\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRCCW7rMgpwc"
      },
      "source": [
        "right now we dont have user data so we will use existing data so this is from sport section football and as we can see the recommandations we are getting some good results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "2QgtgC3UTFSJ",
        "outputId": "316fc9fe-b3a1-45bf-e303-f765a879ed7d"
      },
      "source": [
        "recommander(data['tags'][789:800] , 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It took 0.007288932800292969 seconds to query forest.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Sub_Category</th>\n",
              "      <th>Title</th>\n",
              "      <th>Synopsis</th>\n",
              "      <th>News</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>PV Sindhu eyes China Open after World Champion...</td>\n",
              "      <td>PV Sindhu ended India's long wait for a world ...</td>\n",
              "      <td>World champion PV Sindhu will look to reassert...</td>\n",
              "      <td>Indian China Changzhou Sindhu India Basel Swit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>719</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Football</td>\n",
              "      <td>Mount delivers again for Lampard as Chelsea ek...</td>\n",
              "      <td>Four months into the season and Chelsea manage...</td>\n",
              "      <td>Four months into the season and Chelsea manage...</td>\n",
              "      <td>Chelsea Frank Lampard $300 million Mason Mount...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>881</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Football</td>\n",
              "      <td>Lionel Messi’s salary at Barcelona unsustainab...</td>\n",
              "      <td>Lionel Messi, who sought an exit from Barcelon...</td>\n",
              "      <td>Lionel Messi’s salary is too big for Barcelona...</td>\n",
              "      <td>Lionel Messi Barcelona Emili Rousaud Messi Bar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>French Open: Satwik/Chirag continue golden run...</td>\n",
              "      <td>French Open: Saina Nehwal suffered a 20-22, 21...</td>\n",
              "      <td>Satwiksairaj Rankireddy and Chirag Shetty stor...</td>\n",
              "      <td>Satwiksairaj Rankireddy Chirag Shetty the Fren...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>789</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Football</td>\n",
              "      <td>Lionel Messi returns for Barcelona as Koeman w...</td>\n",
              "      <td>Lionel Messi has stated he will not decide his...</td>\n",
              "      <td>Lionel Messi has recovered from an ankle injur...</td>\n",
              "      <td>Lionel Messi Huesca Barcelona La Liga Eibar Ro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>BWF Rankings: Satwik-Chirag reclaim top-10 spo...</td>\n",
              "      <td>PV Sindhu and Saina Nehwal remained static at ...</td>\n",
              "      <td>Indian men’s doubles pairing of Satwiksairaj R...</td>\n",
              "      <td>Indian Satwiksairaj Rankireddy Chirag Shetty B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>984</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Football</td>\n",
              "      <td>Lionel Messi pays tribute to Diego Maradona in...</td>\n",
              "      <td>After scoring Barcelona's fourth goal, Lionel ...</td>\n",
              "      <td>Lionel Messi paid a personal tribute to the la...</td>\n",
              "      <td>Lionel Messi Diego Maradona Barcelona Osasuna ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>892</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Football</td>\n",
              "      <td>Lionel Messi fires anxious Barcelona to victor...</td>\n",
              "      <td>The win lifted Barcelona up to eighth in the s...</td>\n",
              "      <td>Lionel Messi dragged a nervous Barcelona to a ...</td>\n",
              "      <td>Lionel Messi Barcelona Levante La Liga Catalan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Football</td>\n",
              "      <td>As transfer window opens, struggles of Premier...</td>\n",
              "      <td>With the January transfer window opening, Prem...</td>\n",
              "      <td>The high expectations from new recruits aren’t...</td>\n",
              "      <td>Tottenham Bale Real Madrid Bale Madrid Harry K...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2206</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Wwe-wrestling</td>\n",
              "      <td>WWE Raw Results: The Boss Sasha Banks returns,...</td>\n",
              "      <td>Sasha Banks reemerged on the Raw after SummerS...</td>\n",
              "      <td>Appearing on WWE programming for the first tim...</td>\n",
              "      <td>WWE WrestleMania Sasha Banks SummerSlam Nataly...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Category  ...                                               tags\n",
              "299    Sports  ...  Indian China Changzhou Sindhu India Basel Swit...\n",
              "719    Sports  ...  Chelsea Frank Lampard $300 million Mason Mount...\n",
              "881    Sports  ...  Lionel Messi Barcelona Emili Rousaud Messi Bar...\n",
              "252    Sports  ...  Satwiksairaj Rankireddy Chirag Shetty the Fren...\n",
              "789    Sports  ...  Lionel Messi Huesca Barcelona La Liga Eibar Ro...\n",
              "247    Sports  ...  Indian Satwiksairaj Rankireddy Chirag Shetty B...\n",
              "984    Sports  ...  Lionel Messi Diego Maradona Barcelona Osasuna ...\n",
              "892    Sports  ...  Lionel Messi Barcelona Levante La Liga Catalan...\n",
              "797    Sports  ...  Tottenham Bale Real Madrid Bale Madrid Harry K...\n",
              "2206   Sports  ...  WWE WrestleMania Sasha Banks SummerSlam Nataly...\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjIO1c524p6T"
      },
      "source": [
        "#Creating new user profile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i2xhhYJQxA_"
      },
      "source": [
        "#giving some news from data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYE-DS_EhEo6"
      },
      "source": [
        "Now we will create user profile which we will use to in our recommandation system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO-ICWbY5ksp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "f49d3052-ee25-4068-cc7e-7665b515cd60"
      },
      "source": [
        "data['cat'] = pd.factorize(data['Category'])[0]\n",
        "\n",
        "def factorizer(data):\n",
        "  uci = list(data['cat'].unique())\n",
        "  L=[]\n",
        "  for i in range(len(uci)):\n",
        "      L.append(data.groupby(['cat']).get_group(uci[i]))\n",
        "  for i in L:\n",
        "    i['sub_cat'] , f = pd.factorize(i['Sub_Category'])\n",
        "  for i in range(len(L)):\n",
        "    L[i]['luffy'] = L[i]['cat'].astype(str) + '.' + L[i]['sub_cat'].astype(str)\n",
        "  return L\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Sub_Category</th>\n",
              "      <th>Title</th>\n",
              "      <th>Synopsis</th>\n",
              "      <th>News</th>\n",
              "      <th>tags</th>\n",
              "      <th>cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>BWF World Tour Finals: Fighting PV Sindhu lose...</td>\n",
              "      <td>This was PV Sindhu's 16th defeat to Tai Tzu Yi...</td>\n",
              "      <td>World champion shuttler P V Sindhu went down f...</td>\n",
              "      <td>Tai Tzu Ying Taiwan $1.5 million HSBC BWF Worl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>World Tour Finals Preview: PV Sindhu, recharge...</td>\n",
              "      <td>With the Indian having played more matches tha...</td>\n",
              "      <td>Carolina Marin (50 total) played 24 tournament...</td>\n",
              "      <td>Carolina Marin PV Sindhu Indian Marin Sindhu O...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>Satwiksairaj’s offence gets neutralised by sav...</td>\n",
              "      <td>Satwiksairaj Rankireddy uses big smash to kill...</td>\n",
              "      <td>One would have to be blind to not figure that ...</td>\n",
              "      <td>Satwiksairaj Rankireddy Neutralising Malaysian...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>Dream run of Indian doubles pairs end with sem...</td>\n",
              "      <td>Up against the world number three Thai pair, S...</td>\n",
              "      <td>The Indian mixed doubles pair of Satwiksairaj ...</td>\n",
              "      <td>Indian Satwiksairaj Rankireddy Ashwini Ponnapp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>Satwik-Chirag’s impressive run ends with semif...</td>\n",
              "      <td>The Indian pair had participated in Super 1000...</td>\n",
              "      <td>Tokyo Olympics medal contender Satwiksairaj Ra...</td>\n",
              "      <td>Tokyo Olympics Satwiksairaj Rankireddy Chirag ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5918</th>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Box-office-collection</td>\n",
              "      <td>Kesari box office collection Day 8: Akshay Kum...</td>\n",
              "      <td>Kesari box office collection Day 8: Akshay Kum...</td>\n",
              "      <td>Kesari, starring Akshay Kumar in the lead role...</td>\n",
              "      <td>Kesari Akshay Kumar Rs 105.86 crore Taran Adar...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5919</th>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Box-office-collection</td>\n",
              "      <td>Junglee box office prediction: Vidyut Jammwal ...</td>\n",
              "      <td>Junglee box office prediction: Junglee will ha...</td>\n",
              "      <td>Vidyut Jammwal’s Junglee has caught the fancy ...</td>\n",
              "      <td>Vidyut Jammwal’s Junglee Kesari Notebook Chuck...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5920</th>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Box-office-collection</td>\n",
              "      <td>Luka Chuppi box office collection Day 26: Kart...</td>\n",
              "      <td>Luka Chuppi box office collection Day 26: Krit...</td>\n",
              "      <td>Kriti Sanon and Kartik Aaryan’s film Luka Chup...</td>\n",
              "      <td>Kriti Sanon Kartik Aaryan Luka Chuppi Rs 43 la...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5921</th>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Box-office-collection</td>\n",
              "      <td>Badla box office collection day 20: Going gets...</td>\n",
              "      <td>Badla box office collection day 20: Taapsee Pa...</td>\n",
              "      <td>After more than 2 weeks, Taapsee Pannu’s film ...</td>\n",
              "      <td>Taapsee Pannu’s Badla Badla Rs 1 crore only Rs...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5922</th>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Box-office-collection</td>\n",
              "      <td>Kesari box office collection Day 7: Akshay Kum...</td>\n",
              "      <td>Kesari box office collection Day 7: Akshay Kum...</td>\n",
              "      <td>Akshay Kumar starrer Kesari has become the fas...</td>\n",
              "      <td>Akshay Kumar starrer Kesari Rs 100 crore Gully...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5923 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Category  ... cat\n",
              "0            Sports  ...   0\n",
              "1            Sports  ...   0\n",
              "2            Sports  ...   0\n",
              "3            Sports  ...   0\n",
              "4            Sports  ...   0\n",
              "...             ...  ...  ..\n",
              "5918  Entertainment  ...   3\n",
              "5919  Entertainment  ...   3\n",
              "5920  Entertainment  ...   3\n",
              "5921  Entertainment  ...   3\n",
              "5922  Entertainment  ...   3\n",
              "\n",
              "[5923 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFLUhQ_yhU_D"
      },
      "source": [
        "factorized daata look like this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HasBF0TcWrv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fd27992-669a-45ea-acc3-5a410629772f"
      },
      "source": [
        "L = factorizer(data)\n",
        "L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[     Category   Sub_Category  ... sub_cat luffy\n",
              " 0      Sports      Badminton  ...       0   0.0\n",
              " 1      Sports      Badminton  ...       0   0.0\n",
              " 2      Sports      Badminton  ...       0   0.0\n",
              " 3      Sports      Badminton  ...       0   0.0\n",
              " 4      Sports      Badminton  ...       0   0.0\n",
              " ...       ...            ...  ...     ...   ...\n",
              " 2368   Sports  Wwe-wrestling  ...       6   0.6\n",
              " 2369   Sports  Wwe-wrestling  ...       6   0.6\n",
              " 2370   Sports  Wwe-wrestling  ...       6   0.6\n",
              " 2371   Sports  Wwe-wrestling  ...       6   0.6\n",
              " 2372   Sports  Wwe-wrestling  ...       6   0.6\n",
              " \n",
              " [2373 rows x 9 columns],       Category Sub_Category  ... sub_cat luffy\n",
              " 2373  Business     Aviation  ...       0   1.0\n",
              " 2374  Business     Aviation  ...       0   1.0\n",
              " 2375  Business     Aviation  ...       0   1.0\n",
              " 2376  Business     Aviation  ...       0   1.0\n",
              " 2377  Business     Aviation  ...       0   1.0\n",
              " ...        ...          ...  ...     ...   ...\n",
              " 4101  Business       Market  ...       4   1.4\n",
              " 4102  Business       Market  ...       4   1.4\n",
              " 4103  Business       Market  ...       4   1.4\n",
              " 4104  Business       Market  ...       4   1.4\n",
              " 4105  Business       Market  ...       4   1.4\n",
              " \n",
              " [1733 rows x 9 columns],         Category Sub_Category  ... sub_cat luffy\n",
              " 4106  Technology      Gadgets  ...       0   2.0\n",
              " 4107  Technology      Gadgets  ...       0   2.0\n",
              " 4108  Technology      Gadgets  ...       0   2.0\n",
              " 4109  Technology      Gadgets  ...       0   2.0\n",
              " 4110  Technology      Gadgets  ...       0   2.0\n",
              " ...          ...          ...  ...     ...   ...\n",
              " 5681  Technology      Techook  ...       4   2.4\n",
              " 5682  Technology      Techook  ...       4   2.4\n",
              " 5683  Technology      Techook  ...       4   2.4\n",
              " 5684  Technology      Techook  ...       4   2.4\n",
              " 5685  Technology      Techook  ...       4   2.4\n",
              " \n",
              " [1580 rows x 9 columns],            Category           Sub_Category  ... sub_cat luffy\n",
              " 5686  Entertainment  Box-office-collection  ...       0   3.0\n",
              " 5687  Entertainment  Box-office-collection  ...       0   3.0\n",
              " 5688  Entertainment  Box-office-collection  ...       0   3.0\n",
              " 5689  Entertainment  Box-office-collection  ...       0   3.0\n",
              " 5690  Entertainment  Box-office-collection  ...       0   3.0\n",
              " ...             ...                    ...  ...     ...   ...\n",
              " 5918  Entertainment  Box-office-collection  ...       0   3.0\n",
              " 5919  Entertainment  Box-office-collection  ...       0   3.0\n",
              " 5920  Entertainment  Box-office-collection  ...       0   3.0\n",
              " 5921  Entertainment  Box-office-collection  ...       0   3.0\n",
              " 5922  Entertainment  Box-office-collection  ...       0   3.0\n",
              " \n",
              " [237 rows x 9 columns]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5VNWlJehmv8"
      },
      "source": [
        "Hear we are creating first user interface what he will get on his first time visiting \n",
        "he will get news from  all the section so for firct time we are giving him selection freedom to select his favorit catagories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwKQtzBDu01c"
      },
      "source": [
        "#This is what user will get on his first time\n",
        "\n",
        "def first_time_user(data , num):\n",
        "  sug_ls = []\n",
        "  L = factorizer(data)\n",
        "  for sec in L:\n",
        "    sug = sec.sample(n = num)\n",
        "    sug_ls.append(sug)\n",
        "  sug_df = pd.concat(sug_ls)\n",
        "  return sug_df\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1KhC2faw9AxL",
        "outputId": "75b795f2-98f1-4136-ea40-db11b155196d"
      },
      "source": [
        "first_data = first_time_user(data , 5)\n",
        "first_data = first_data.reset_index()\n",
        "first_data = first_data.drop(['cat', 'sub_cat','luffy'], axis=1)\n",
        "\n",
        "first_data\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Category</th>\n",
              "      <th>Sub_Category</th>\n",
              "      <th>Title</th>\n",
              "      <th>Synopsis</th>\n",
              "      <th>News</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>533</td>\n",
              "      <td>Sports</td>\n",
              "      <td>Cricket</td>\n",
              "      <td>Delhi record second successive win, beat Andhr...</td>\n",
              "      <td>Delhi chased the target with three overs to sp...</td>\n",
              "      <td>Delhi recorded their second straight win in th...</td>\n",
              "      <td>Delhi Andhra Pradesh Elite Group E the Wankhed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>637</td>\n",
              "      <td>Sports</td>\n",
              "      <td>Cricket</td>\n",
              "      <td>Delhi Capitals appoint Pravin Amre as assistan...</td>\n",
              "      <td>Pravin Amre, who earlier served as the franchi...</td>\n",
              "      <td>Indian Premier League (IPL) franchise Delhi Ca...</td>\n",
              "      <td>Indian IPL Delhi Capitals Pravin Amre Amre Del...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2055</td>\n",
              "      <td>Sports</td>\n",
              "      <td>Wwe-wrestling</td>\n",
              "      <td>WWE Hell in a Cell 2020 Live Streaming, Date a...</td>\n",
              "      <td>WWE Hell in a Cell 2020 Live Streaming, Date a...</td>\n",
              "      <td>WWE Hell in a Cell 2020 Live Streaming, Date a...</td>\n",
              "      <td>Universal Championship Jey Uso Cell Jimmy Uso ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1766</td>\n",
              "      <td>Sports</td>\n",
              "      <td>Tennis</td>\n",
              "      <td>Stefanos Tsitsipas reveals injury scare ahead ...</td>\n",
              "      <td>Stefanos Tsitsipas said he had picked up a leg...</td>\n",
              "      <td>Stefanos Tsitsipas says he is unsure how his A...</td>\n",
              "      <td>Stefanos Tsitsipas Greek the Paris Masters ATP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>199</td>\n",
              "      <td>Sports</td>\n",
              "      <td>Badminton</td>\n",
              "      <td>World conqueror PV Sindhu, fast-rising Lakshya...</td>\n",
              "      <td>In doubles, Satwiksairaj Rankireddy and Chirag...</td>\n",
              "      <td>A momentous gold at the world championships mo...</td>\n",
              "      <td>the world championships Lakshya Sen Indian 201...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2902</td>\n",
              "      <td>Business</td>\n",
              "      <td>Banking-and-finance</td>\n",
              "      <td>Falling cash usage in May-Jul: Transaction val...</td>\n",
              "      <td>During May, June, and July, for example, the t...</td>\n",
              "      <td>Mounting job losses and salary cuts across sec...</td>\n",
              "      <td>the National Payments Corporation of India NPC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4031</td>\n",
              "      <td>Business</td>\n",
              "      <td>Market</td>\n",
              "      <td>Sebi shortlists Bharti Airtel, Wipro, others t...</td>\n",
              "      <td>The other shortlisted companies are -- Hewlett...</td>\n",
              "      <td>Markets regulator Sebi has shortlisted eight c...</td>\n",
              "      <td>Sebi Bharti Airtel Wipro Tata Communications H...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3391</td>\n",
              "      <td>Business</td>\n",
              "      <td>Companies</td>\n",
              "      <td>Bajaj Auto posts 9 per cent fall in total sale...</td>\n",
              "      <td>Total domestic sales in August stood at 1,85,8...</td>\n",
              "      <td>Bajaj Auto on Wednesday reported a 9 per cent ...</td>\n",
              "      <td>Bajaj Auto 9 per cent Pune 1,85,879 11 per cen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2865</td>\n",
              "      <td>Business</td>\n",
              "      <td>Banking-and-finance</td>\n",
              "      <td>SC protect accounts, which were not declared N...</td>\n",
              "      <td>The apex court passed the order while noting t...</td>\n",
              "      <td>The Supreme Court Thursday directed that accou...</td>\n",
              "      <td>The Supreme Court NPA Ashok Bhushan The apex c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3354</td>\n",
              "      <td>Business</td>\n",
              "      <td>Companies</td>\n",
              "      <td>Toyota Kirloskar Motor reiterates its commitme...</td>\n",
              "      <td>Toyota Kirloskar Motor (TKM) is a joint ventur...</td>\n",
              "      <td>Toyota Kirloskar Motor (TKM) on Thursday said ...</td>\n",
              "      <td>Toyota Kirloskar Motor TKM Indian India Innova...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5228</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Science</td>\n",
              "      <td>A piece of Moon on sale; you can have it for R...</td>\n",
              "      <td>This 13.5kg piece of rock, dubbed NWA 12691, i...</td>\n",
              "      <td>Countless poets and lyricists have spoken abou...</td>\n",
              "      <td>Moon British Christie’s the moon The 13.5kg Ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4299</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Gadgets</td>\n",
              "      <td>Amazon Echo Show 8 comes to India, will cost R...</td>\n",
              "      <td>Amazon's new Echo Show 8 adds an 8-inch HD scr...</td>\n",
              "      <td>Amazon is adding a new member to the Echo Show...</td>\n",
              "      <td>Amazon Amazon the Echo Show 8 Echo The Echo Sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4559</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Laptops</td>\n",
              "      <td>Dell brings Alienware Area-m51 customisable ga...</td>\n",
              "      <td>Dell's Alienware has launched the Area-51m lap...</td>\n",
              "      <td>Dell’s Alienware has launched the Area-51m lap...</td>\n",
              "      <td>Dell Alienware Area-51 India Rs 299,590 Area-5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4980</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Tech-reviews</td>\n",
              "      <td>iOS 13 beta preview: Ability to edit photos an...</td>\n",
              "      <td>Apple iOS 13 does not usher in a radical chang...</td>\n",
              "      <td>The next iPhones will usher in iOS 13 for Appl...</td>\n",
              "      <td>iOS 13 Apple the Public Beta of the Apple iOS ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>4598</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Laptops</td>\n",
              "      <td>Microsoft Surface Laptop 2 could launch in bla...</td>\n",
              "      <td>Microsoft is apparently preparing to launch th...</td>\n",
              "      <td>Microsoft is apparently preparing to launch th...</td>\n",
              "      <td>Microsoft the Surface Laptop 2 Windows United ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>5707</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Box-office-collection</td>\n",
              "      <td>Bhoot The Haunted Ship box office prediction: ...</td>\n",
              "      <td>Vicky Kaushal is returning to the big screen w...</td>\n",
              "      <td>Vicky Kaushal gave the year 2019 a perfect sta...</td>\n",
              "      <td>Vicky Kaushal The Surgical Strike Rs 8.20 cror...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>5695</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Box-office-collection</td>\n",
              "      <td>Bollywood box office: Thappad gets decent open...</td>\n",
              "      <td>Anubhav Sinha directorial Thappad starring Taa...</td>\n",
              "      <td>Taapsee Pannu starrer Thappad that released on...</td>\n",
              "      <td>Rs 3.07 crore Taran Adarsh Twitter #Delhi #NCR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>5834</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Box-office-collection</td>\n",
              "      <td>Batla House box office collection Day 4: John ...</td>\n",
              "      <td>Batla House box office collection Day 4: John ...</td>\n",
              "      <td>John Abraham film Batla House, which released ...</td>\n",
              "      <td>John Abraham Batla House Akshay Kumar starrer ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>5719</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Box-office-collection</td>\n",
              "      <td>Bollywood box office: Tanhaji gives new releas...</td>\n",
              "      <td>Bollywood box office: Ajay Devgn's Tanhaji con...</td>\n",
              "      <td>Jawaani Jaaneman and Street Dancer 3D are faci...</td>\n",
              "      <td>Jawaani Jaaneman Street Dancer 3D Tanhaji The ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>5743</td>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Box-office-collection</td>\n",
              "      <td>Chhapaak box office collection Day 3: Deepika ...</td>\n",
              "      <td>Chhapaak box office collection Day 3: Deepika ...</td>\n",
              "      <td>Deepika Padukone’s latest release Chhapaak is ...</td>\n",
              "      <td>Deepika Padukone’s Chhapaak Ajay Devgn Tanhaji...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index  ...                                               tags\n",
              "0     533  ...  Delhi Andhra Pradesh Elite Group E the Wankhed...\n",
              "1     637  ...  Indian IPL Delhi Capitals Pravin Amre Amre Del...\n",
              "2    2055  ...  Universal Championship Jey Uso Cell Jimmy Uso ...\n",
              "3    1766  ...  Stefanos Tsitsipas Greek the Paris Masters ATP...\n",
              "4     199  ...  the world championships Lakshya Sen Indian 201...\n",
              "5    2902  ...  the National Payments Corporation of India NPC...\n",
              "6    4031  ...  Sebi Bharti Airtel Wipro Tata Communications H...\n",
              "7    3391  ...  Bajaj Auto 9 per cent Pune 1,85,879 11 per cen...\n",
              "8    2865  ...  The Supreme Court NPA Ashok Bhushan The apex c...\n",
              "9    3354  ...  Toyota Kirloskar Motor TKM Indian India Innova...\n",
              "10   5228  ...  Moon British Christie’s the moon The 13.5kg Ch...\n",
              "11   4299  ...  Amazon Amazon the Echo Show 8 Echo The Echo Sh...\n",
              "12   4559  ...  Dell Alienware Area-51 India Rs 299,590 Area-5...\n",
              "13   4980  ...  iOS 13 Apple the Public Beta of the Apple iOS ...\n",
              "14   4598  ...  Microsoft the Surface Laptop 2 Windows United ...\n",
              "15   5707  ...  Vicky Kaushal The Surgical Strike Rs 8.20 cror...\n",
              "16   5695  ...  Rs 3.07 crore Taran Adarsh Twitter #Delhi #NCR...\n",
              "17   5834  ...  John Abraham Batla House Akshay Kumar starrer ...\n",
              "18   5719  ...  Jawaani Jaaneman Street Dancer 3D Tanhaji The ...\n",
              "19   5743  ...  Deepika Padukone’s Chhapaak Ajay Devgn Tanhaji...\n",
              "\n",
              "[20 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy7-TTlqiB89"
      },
      "source": [
        "We have 5-5 news form each section so user will select 5 news "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlQFg7qK9DFb",
        "outputId": "db59bbbd-a708-46dd-c3e9-b0cc382181c3"
      },
      "source": [
        "def user_selection(first_data):\n",
        "  in_idx = []\n",
        "  for i in range(0 ,5):\n",
        "    inp = int(input('input index no of the news  : '))\n",
        "    in_idx.append(inp)\n",
        "    idx_ls = []\n",
        "    for idx in in_idx:\n",
        "      idx_d = idx_to_df(idx , first_data)\n",
        "      idx_ls.append(idx_d)\n",
        "    idx_df = pd.concat(idx_ls)\n",
        "\n",
        "  return idx_df\n",
        "user_df = user_selection(first_data)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input index no of the news  : 0\n",
            "input index no of the news  : 1\n",
            "input index no of the news  : 2\n",
            "input index no of the news  : 17\n",
            "input index no of the news  : 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVkghbAZip4v"
      },
      "source": [
        "as above we've created the user profile for the first user which will give some recommandations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tUBL8RDi76d"
      },
      "source": [
        "And as we can seeeee've selected some sports news and Entertainment\tnews and we are getting recommandations from the same secton so our recommandation system is working well. Even in sports section we've selected crickt and Wwe-wrestling\t sub section and as we can see we are getting recommandations from the same section wonderful...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "QWkBepoMLfta",
        "outputId": "63dca996-bc79-480e-f2e6-85b16a8a6d77"
      },
      "source": [
        "recommander(user_df['tags'] , 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It took 0.005433082580566406 seconds to query forest.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Sub_Category</th>\n",
              "      <th>Title</th>\n",
              "      <th>Synopsis</th>\n",
              "      <th>News</th>\n",
              "      <th>tags</th>\n",
              "      <th>cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5792</th>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Box-office-collection</td>\n",
              "      <td>War box office collection Day 15: Hrithik-Tige...</td>\n",
              "      <td>War box office collection Day 15: The YRF acti...</td>\n",
              "      <td>Hrithik Roshan and Tiger Shroff starrer War is...</td>\n",
              "      <td>Hrithik Roshan Tiger Shroff Rs 300 crore Rs 53...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2055</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Wwe-wrestling</td>\n",
              "      <td>WWE Hell in a Cell 2020 Live Streaming, Date a...</td>\n",
              "      <td>WWE Hell in a Cell 2020 Live Streaming, Date a...</td>\n",
              "      <td>WWE Hell in a Cell 2020 Live Streaming, Date a...</td>\n",
              "      <td>Universal Championship Jey Uso Cell Jimmy Uso ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>649</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Cricket</td>\n",
              "      <td>Navdeep will rise to the occasion if handed a ...</td>\n",
              "      <td>Does the scrawny pacer from Taraori, Haryana, ...</td>\n",
              "      <td>Navdeep Saini is yet to make his Test debut, e...</td>\n",
              "      <td>Navdeep Saini India Umesh Yadav Saini Sydney T...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5802</th>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Box-office-collection</td>\n",
              "      <td>War box office prediction: Hrithik Roshan and ...</td>\n",
              "      <td>Releasing in over 4000 screens, Hrithik Roshan...</td>\n",
              "      <td>The Gandhi Jayanti release of the year, War, s...</td>\n",
              "      <td>Gandhi Jayanti War Hrithik Roshan Tiger Shroff...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Cricket</td>\n",
              "      <td>Rajasthan Royals release Steve Smith; Chennai ...</td>\n",
              "      <td>Rajasthan Royals have also appointed former Sr...</td>\n",
              "      <td>The IPL player retention/release day doesn’t o...</td>\n",
              "      <td>IPL IPL IPL Samson RoyalsRajasthan Royals Stev...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3281</th>\n",
              "      <td>Business</td>\n",
              "      <td>Companies</td>\n",
              "      <td>Cox &amp; Kings loaned out Rs 6,071 crore to at le...</td>\n",
              "      <td>The travel firm came under the lens after the ...</td>\n",
              "      <td>A forensic audit of Cox &amp; Kings Ltd, the liste...</td>\n",
              "      <td>Cox &amp; Kings Ltd the Enforcement Directorate th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Cricket</td>\n",
              "      <td>Delhi record second successive win, beat Andhr...</td>\n",
              "      <td>Delhi chased the target with three overs to sp...</td>\n",
              "      <td>Delhi recorded their second straight win in th...</td>\n",
              "      <td>Delhi Andhra Pradesh Elite Group E the Wankhed...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2070</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Wwe-wrestling</td>\n",
              "      <td>Triple H: Covid-19 has made this time frame ‘i...</td>\n",
              "      <td>Triple H opens up about the difficulties WWE f...</td>\n",
              "      <td>World Wrestling Federation (WWE) has managed t...</td>\n",
              "      <td>World Wrestling Federation WWE WWE Paul Michae...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2071</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Wwe-wrestling</td>\n",
              "      <td>Slams, not dunks: WWE replaces NBA at one Flor...</td>\n",
              "      <td>Pro wrestling is replacing pro basketball at t...</td>\n",
              "      <td>Pro wrestling is replacing pro basketball at t...</td>\n",
              "      <td>Florida WWE the Amway Center Orlando NBA The O...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>606</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Cricket</td>\n",
              "      <td>Syed Mushtaq Ali T20 Trophy 2020/21: Schedule,...</td>\n",
              "      <td>Syed Mushtaq Ali T20 Trophy 2020/21: All you n...</td>\n",
              "      <td>Domestic cricket finally returns to India afte...</td>\n",
              "      <td>India Ranji Trophy Indian Mushtaq Ali T20 Trop...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Category  ... cat\n",
              "5792  Entertainment  ...   3\n",
              "2055         Sports  ...   0\n",
              "649          Sports  ...   0\n",
              "5802  Entertainment  ...   3\n",
              "431          Sports  ...   0\n",
              "3281       Business  ...   1\n",
              "533          Sports  ...   0\n",
              "2070         Sports  ...   0\n",
              "2071         Sports  ...   0\n",
              "606          Sports  ...   0\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usWduJuWjqxN"
      },
      "source": [
        "Now we will create a profile for the old user "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmuejY9ajquI"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baX-PeYCT2Vi"
      },
      "source": [
        "def old_user(data ,num):\n",
        "  selection = first_time_user(data , num)\n",
        "  selection = selection.reset_index()\n",
        "  selection = selection.drop(['cat', 'sub_cat','luffy'], axis=1)\n",
        "  user_data = selection[['index', 'tags']]\n",
        "  return user_data\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR_A5dSqj2Zk"
      },
      "source": [
        "We have generated this clickstream data in saparate ipynb file that we've attached"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "tVAcvB5rwmWV",
        "outputId": "4c46d301-7374-4103-fb0f-ff0f3973cd0d"
      },
      "source": [
        "cs = pd.read_csv('/content/gdrive/MyDrive/StrawHats projects/StrawHats_clickstream.csv')\n",
        "cs = cs.drop(['Unnamed: 0','served_section','Catagory','Sub_Catagory'], axis=1)\n",
        "cs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Click</th>\n",
              "      <th>UserID</th>\n",
              "      <th>Time_Spent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.764861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.635004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149995</th>\n",
              "      <td>1</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.806663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149996</th>\n",
              "      <td>1</td>\n",
              "      <td>100.0</td>\n",
              "      <td>11.005164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149997</th>\n",
              "      <td>1</td>\n",
              "      <td>100.0</td>\n",
              "      <td>10.909229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149998</th>\n",
              "      <td>1</td>\n",
              "      <td>100.0</td>\n",
              "      <td>17.250826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149999</th>\n",
              "      <td>1</td>\n",
              "      <td>100.0</td>\n",
              "      <td>16.754506</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Click  UserID  Time_Spent\n",
              "0           0     1.0    0.000000\n",
              "1           1     1.0    1.764861\n",
              "2           1     1.0    0.635004\n",
              "3           1     1.0    0.000000\n",
              "4           0     1.0    0.000000\n",
              "...       ...     ...         ...\n",
              "149995      1   100.0    8.806663\n",
              "149996      1   100.0   11.005164\n",
              "149997      1   100.0   10.909229\n",
              "149998      1   100.0   17.250826\n",
              "149999      1   100.0   16.754506\n",
              "\n",
              "[150000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XL2oEfnkFJe"
      },
      "source": [
        "Hear we are taking just one user to represent so we are taking following notes\n",
        "\n",
        "\n",
        "1) our user's intrusts so user will spnt their most of the time in their intrest section\n",
        "\n",
        "\n",
        "2) Not repetitive recommandations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "HOe4_WAUx5Sp",
        "outputId": "146dc059-601d-4bf6-85b5-0c3fe2e025e7"
      },
      "source": [
        "user_selection = old_user(data, 20)\n",
        "user_1 = cs[cs['UserID'] == 1.0].sample( n = 80)\n",
        "user_1 = user_1.reset_index()\n",
        "user_1 = user_1.drop(['index'],axis=1)\n",
        "user_1 = user_1.join(user_selection)\n",
        "user_1.sort_values(\"Time_Spent\", axis = 0, ascending = False,\n",
        "                 inplace = True, na_position ='first')\n",
        "user_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Click</th>\n",
              "      <th>UserID</th>\n",
              "      <th>Time_Spent</th>\n",
              "      <th>index</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.250826</td>\n",
              "      <td>1002</td>\n",
              "      <td>India Hardik Pandya ODI Australia Virat Kohli ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.250826</td>\n",
              "      <td>3060</td>\n",
              "      <td>the Reserve Bank of India HDFC Bank overdues H...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.250826</td>\n",
              "      <td>1822</td>\n",
              "      <td>Serena Williams the French Open Kristie Ahn Wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.250826</td>\n",
              "      <td>5556</td>\n",
              "      <td>OnePlus Pete Lau Weibo OnePlus 8 OnePlus Rs 42...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.250826</td>\n",
              "      <td>3507</td>\n",
              "      <td>The Finance Ministry Rs 9,879.61 Ministry Tami...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1457</td>\n",
              "      <td>Lewis Hamilton Briton George Floyd Minneapolis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4193</td>\n",
              "      <td>Amazfit Neo Amazfit Neo Caravaan India Rs The ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4929</td>\n",
              "      <td>Vivo Vivo four-pixel Vivo V17 Pro’s USP Macro ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>924</td>\n",
              "      <td>Kerala Blasters’ FC Goa the Indian Super Leagu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4111</td>\n",
              "      <td>India Bose Sony Jabra Sennheiser Amazon Great ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Click  UserID  ...  index                                               tags\n",
              "2       1     1.0  ...   1002  India Hardik Pandya ODI Australia Virat Kohli ...\n",
              "27      1     1.0  ...   3060  the Reserve Bank of India HDFC Bank overdues H...\n",
              "14      1     1.0  ...   1822  Serena Williams the French Open Kristie Ahn Wi...\n",
              "49      1     1.0  ...   5556  OnePlus Pete Lau Weibo OnePlus 8 OnePlus Rs 42...\n",
              "24      1     1.0  ...   3507  The Finance Ministry Rs 9,879.61 Ministry Tami...\n",
              "..    ...     ...  ...    ...                                                ...\n",
              "9       0     1.0  ...   1457  Lewis Hamilton Briton George Floyd Minneapolis...\n",
              "54      1     1.0  ...   4193  Amazfit Neo Amazfit Neo Caravaan India Rs The ...\n",
              "43      0     1.0  ...   4929  Vivo Vivo four-pixel Vivo V17 Pro’s USP Macro ...\n",
              "17      1     1.0  ...    924  Kerala Blasters’ FC Goa the Indian Super Leagu...\n",
              "51      0     1.0  ...   4111  India Bose Sony Jabra Sennheiser Amazon Great ...\n",
              "\n",
              "[80 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT9ibh29k_P1"
      },
      "source": [
        "Lets test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WycjwCOd7v6z",
        "outputId": "1e2f9330-f7fd-402e-f20f-3da823c5e473"
      },
      "source": [
        "user_1['tags'][:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2     India Hardik Pandya ODI Australia Virat Kohli ...\n",
              "27    the Reserve Bank of India HDFC Bank overdues H...\n",
              "14    Serena Williams the French Open Kristie Ahn Wi...\n",
              "49    OnePlus Pete Lau Weibo OnePlus 8 OnePlus Rs 42...\n",
              "24    The Finance Ministry Rs 9,879.61 Ministry Tami...\n",
              "Name: tags, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "9AOgpQdP5_n5",
        "outputId": "29419e9e-d01d-4d90-8b0e-c62fb4cb20f6"
      },
      "source": [
        "recommander(user_1['tags'][:5] , 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It took 0.004212379455566406 seconds to query forest.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Sub_Category</th>\n",
              "      <th>Title</th>\n",
              "      <th>Synopsis</th>\n",
              "      <th>News</th>\n",
              "      <th>tags</th>\n",
              "      <th>cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>963</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Football</td>\n",
              "      <td>Champions League wrap: Liverpool and Porto adv...</td>\n",
              "      <td>Zinedine Zidane’s side would have advanced wit...</td>\n",
              "      <td>While former champions Liverpool and Porto eas...</td>\n",
              "      <td>Liverpool Porto the Champions League Real Madr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>677</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Football</td>\n",
              "      <td>Thomas Tuchel appointed Chelsea manager follow...</td>\n",
              "      <td>Thomas Tuchel, the former Borussia Dortmund an...</td>\n",
              "      <td>Thomas Tuchel became the latest manager to tak...</td>\n",
              "      <td>Thomas Tuchel Chelsea Premier League German Fr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5223</th>\n",
              "      <td>Technology</td>\n",
              "      <td>Science</td>\n",
              "      <td>Future warming arriving earlier than expected,...</td>\n",
              "      <td>Dozens of extreme events have occurred along t...</td>\n",
              "      <td>Climate scientists have previously warned that...</td>\n",
              "      <td>Science Advances The emergence of heat and hum...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1610</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Motor-sport</td>\n",
              "      <td>Azerbaijan GP: Charles Leclerc leads Ferrari p...</td>\n",
              "      <td>Charles Leclerc set a scorching pace on an inc...</td>\n",
              "      <td>Charles Leclerc set a scorching pace on an inc...</td>\n",
              "      <td>Charles Leclerc Azerbaijan Grand Prix Ferrari ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3409</th>\n",
              "      <td>Business</td>\n",
              "      <td>Companies</td>\n",
              "      <td>Ducati launches all-new Panigale V2 in India, ...</td>\n",
              "      <td>The superbike is powered by a 955-cc BS-VI eng...</td>\n",
              "      <td>Italian superbike maker Ducati on Wednesday sa...</td>\n",
              "      <td>Italian Ducati Panigale India Rs 16.99 lakh BS...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2289</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Wwe-wrestling</td>\n",
              "      <td>WWE Raw: Kurt Angle announces his WrestleMania...</td>\n",
              "      <td>WWE Raw witnessed Kurt Angle finally opening t...</td>\n",
              "      <td>Kurt Angle has an opponent for his final match...</td>\n",
              "      <td>Kurt Angle John Cena Shelton Benjamin the WWE ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1395</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Motor-sport</td>\n",
              "      <td>Mercedes F1 team member tests positive for COV...</td>\n",
              "      <td>Formula 1 last week reported 10 positive COVID...</td>\n",
              "      <td>Formula One champions Mercedes reported on Thu...</td>\n",
              "      <td>Mercedes Lewis Hamilton Valtteri Bottas Britis...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1175</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Hockey</td>\n",
              "      <td>India men to face Russia, women draw USA in fi...</td>\n",
              "      <td>Eight-time Olympic champions India men are ran...</td>\n",
              "      <td>In a favourable draw, India’s men’s hockey tea...</td>\n",
              "      <td>India Russia the Tokyo Olympics Russian Russia...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1720</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Tennis</td>\n",
              "      <td>Tennis in 2020: Novak Djokovic’s mixed year to...</td>\n",
              "      <td>The Tennis Yearender: The covid interruption, ...</td>\n",
              "      <td>Novak Djokovic remained the highlight of tenni...</td>\n",
              "      <td>Novak Djokovic Australian Serbian DjokovicDjok...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1822</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Tennis</td>\n",
              "      <td>French Open 2020: Serena Williams reaches seco...</td>\n",
              "      <td>Serena Williams is a three-time French Open ch...</td>\n",
              "      <td>Serena Williams advanced to the second round o...</td>\n",
              "      <td>Serena Williams the French Open Kristie Ahn Wi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Category  ... cat\n",
              "963       Sports  ...   0\n",
              "677       Sports  ...   0\n",
              "5223  Technology  ...   2\n",
              "1610      Sports  ...   0\n",
              "3409    Business  ...   1\n",
              "2289      Sports  ...   0\n",
              "1395      Sports  ...   0\n",
              "1175      Sports  ...   0\n",
              "1720      Sports  ...   0\n",
              "1822      Sports  ...   0\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "Tj4Q4Tc_6jy_",
        "outputId": "6e303aba-b5df-48e6-8a99-ba447d197f43"
      },
      "source": [
        "def user_recommandaton(user_data_tags):\n",
        "    re_1 = user_data_tags[:2]\n",
        "    re_2 = user_data_tags[2:4]\n",
        "    re_3 = user_data_tags[4:6]\n",
        "    re_4 = user_data_tags[6:8]\n",
        "    re_5 = user_data_tags[8:10]\n",
        "    re = [re_1, re_2, re_3, re_4, re_5]\n",
        "    recommandations = []\n",
        "    for i in re:\n",
        "      user_reco = recommander(i , 2)\n",
        "      recommandations.append(user_reco)\n",
        "    recommandations = pd.concat(recommandations)\n",
        "    return recommandations\n",
        "user_recommandaton(user_1['tags'])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It took 0.003020763397216797 seconds to query forest.\n",
            "It took 0.003388643264770508 seconds to query forest.\n",
            "It took 0.003313779830932617 seconds to query forest.\n",
            "It took 0.003461122512817383 seconds to query forest.\n",
            "It took 0.0029435157775878906 seconds to query forest.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Sub_Category</th>\n",
              "      <th>Title</th>\n",
              "      <th>Synopsis</th>\n",
              "      <th>News</th>\n",
              "      <th>tags</th>\n",
              "      <th>cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2976</th>\n",
              "      <td>Business</td>\n",
              "      <td>Banking-and-finance</td>\n",
              "      <td>RBI proposes to limit tenures of CEOs &amp; whole-...</td>\n",
              "      <td>The RBI has said it is desirable to limit the ...</td>\n",
              "      <td>The Reserve Bank of India has proposed to rest...</td>\n",
              "      <td>The Reserve Bank of India RBI WTD the Departme...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3049</th>\n",
              "      <td>Business</td>\n",
              "      <td>Banking-and-finance</td>\n",
              "      <td>Reserve Bank puts on hold two key HDFC Bank ap...</td>\n",
              "      <td>The RBI move, which came over four months afte...</td>\n",
              "      <td>The Reserve Bank of India (RBI) has put on hol...</td>\n",
              "      <td>The Reserve Bank of India Sashidhar Jagdishan ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1540</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Motor-sport</td>\n",
              "      <td>Formula 1: Valtteri Bottas takes US pole, Lewi...</td>\n",
              "      <td>Valtteri Bottas will need a victory on Sunday ...</td>\n",
              "      <td>Mercedes’ Valtteri Bottas snatched pole positi...</td>\n",
              "      <td>Mercedes Valtteri Bottas the U.S. Grand Prix L...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1822</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Tennis</td>\n",
              "      <td>French Open 2020: Serena Williams reaches seco...</td>\n",
              "      <td>Serena Williams is a three-time French Open ch...</td>\n",
              "      <td>Serena Williams advanced to the second round o...</td>\n",
              "      <td>Serena Williams the French Open Kristie Ahn Wi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2131</th>\n",
              "      <td>Sports</td>\n",
              "      <td>Wwe-wrestling</td>\n",
              "      <td>On Stone Cold Steve Austin Day, Coronavirus cr...</td>\n",
              "      <td>Stone Cold Steve Austin asked for a hell yeah ...</td>\n",
              "      <td>Stone Cold Steve Austin has been one of the mo...</td>\n",
              "      <td>Steve Austin WWE the Royal Rumble Austin 3:16”...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5755</th>\n",
              "      <td>Entertainment</td>\n",
              "      <td>Box-office-collection</td>\n",
              "      <td>Dabangg 3 box office collection prediction: Sa...</td>\n",
              "      <td>Considering the box office success of the last...</td>\n",
              "      <td>Chulbul Robinhood Pandey aka Salman Khan is re...</td>\n",
              "      <td>Chulbul Robinhood Pandey Salman Khan Dabangg D...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5596</th>\n",
              "      <td>Technology</td>\n",
              "      <td>Techook</td>\n",
              "      <td>The best smart speakers under Rs 20,000 in 2020</td>\n",
              "      <td>If you are looking for a smart speaker to cont...</td>\n",
              "      <td>Smart speakers are in the rage these days as m...</td>\n",
              "      <td>Bluetooth Apple HomePod Apple iOS Apple HomeKi...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4573</th>\n",
              "      <td>Technology</td>\n",
              "      <td>Laptops</td>\n",
              "      <td>Acer Swift 7 with thin bezels, compact design ...</td>\n",
              "      <td>CES 2019: Acer's Swift 7 features a high-resol...</td>\n",
              "      <td>At CES 2019, Acer has launched the Swift 7 not...</td>\n",
              "      <td>CES 2019 Acer Swift 7 92 per cent Intel Core 9...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4112</th>\n",
              "      <td>Technology</td>\n",
              "      <td>Gadgets</td>\n",
              "      <td>LG’s new Ultrafine Ergo 4K monitor can be swiv...</td>\n",
              "      <td>The LG Ultrafine Ergo monitor can be tilted in...</td>\n",
              "      <td>LG has  launched its new Ultrafine Display Erg...</td>\n",
              "      <td>LG Ultrafine Display Ergo India The LG 32UN880...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2695</th>\n",
              "      <td>Business</td>\n",
              "      <td>Aviation</td>\n",
              "      <td>Air India needs to survive till it is sold: CM...</td>\n",
              "      <td>Civil Aviation Minister Hardeep Singh Puri had...</td>\n",
              "      <td>As the central government is planning to invit...</td>\n",
              "      <td>Air India CMD Facebook Air India Ashwani Lohan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Category  ... cat\n",
              "2976       Business  ...   1\n",
              "3049       Business  ...   1\n",
              "1540         Sports  ...   0\n",
              "1822         Sports  ...   0\n",
              "2131         Sports  ...   0\n",
              "5755  Entertainment  ...   3\n",
              "5596     Technology  ...   2\n",
              "4573     Technology  ...   2\n",
              "4112     Technology  ...   2\n",
              "2695       Business  ...   1\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtGqMjmsmUV2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w04AGK4jlTZ9"
      },
      "source": [
        "So hear we are getting all the recommandations for one old user and we are getting preety good recommandations for old user also."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wrt0mvodllc7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Szr9thgwpO0e"
      },
      "source": [
        "Similarly we can give recommandations to all the users"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1RmtVvOLvMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3be77ecb-93ba-4604-d064-b8bcad1454fd"
      },
      "source": [
        "user_id = cs['UserID'].unique()\n",
        "user_id = user_id.tolist()\n",
        "user = []\n",
        "for i in user_id:\n",
        "  user_selection = old_user(data, 20)\n",
        "  user_1 = cs[cs['UserID'] == i].sample( n = 80)\n",
        "  user_1 = user_1.reset_index()\n",
        "  user_1 = user_1.drop(['index'],axis=1)\n",
        "  user_1 = user_1.join(user_selection)\n",
        "  user_1.sort_values(\"Time_Spent\", axis = 0, ascending = False,\n",
        "                  inplace = True, na_position ='first')\n",
        "  user.append(user_1)\n",
        "rec_for_all = []\n",
        "for L in user:\n",
        "  L = L['tags']\n",
        "  rec = user_recommandaton(L)\n",
        "  rec_for_all.append(rec)\n",
        "rec_for_all\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "It took 0.006429433822631836 seconds to query forest.\n",
            "It took 0.003559589385986328 seconds to query forest.\n",
            "It took 0.0045359134674072266 seconds to query forest.\n",
            "It took 0.0035538673400878906 seconds to query forest.\n",
            "It took 0.003489255905151367 seconds to query forest.\n",
            "It took 0.003573894500732422 seconds to query forest.\n",
            "It took 0.003138303756713867 seconds to query forest.\n",
            "It took 0.003746509552001953 seconds to query forest.\n",
            "It took 0.0025606155395507812 seconds to query forest.\n",
            "It took 0.003406047821044922 seconds to query forest.\n",
            "It took 0.0029611587524414062 seconds to query forest.\n",
            "It took 0.0031583309173583984 seconds to query forest.\n",
            "It took 0.003000497817993164 seconds to query forest.\n",
            "It took 0.004415035247802734 seconds to query forest.\n",
            "It took 0.003400564193725586 seconds to query forest.\n",
            "It took 0.0035936832427978516 seconds to query forest.\n",
            "It took 0.00321197509765625 seconds to query forest.\n",
            "It took 0.0029888153076171875 seconds to query forest.\n",
            "It took 0.0031752586364746094 seconds to query forest.\n",
            "It took 0.0037004947662353516 seconds to query forest.\n",
            "It took 0.004002809524536133 seconds to query forest.\n",
            "It took 0.0037496089935302734 seconds to query forest.\n",
            "It took 0.003488302230834961 seconds to query forest.\n",
            "It took 0.0032618045806884766 seconds to query forest.\n",
            "It took 0.0034813880920410156 seconds to query forest.\n",
            "It took 0.0033173561096191406 seconds to query forest.\n",
            "It took 0.0032672882080078125 seconds to query forest.\n",
            "It took 0.003326416015625 seconds to query forest.\n",
            "It took 0.002942800521850586 seconds to query forest.\n",
            "It took 0.0035779476165771484 seconds to query forest.\n",
            "It took 0.004071712493896484 seconds to query forest.\n",
            "It took 0.0031223297119140625 seconds to query forest.\n",
            "It took 0.003322601318359375 seconds to query forest.\n",
            "It took 0.004069089889526367 seconds to query forest.\n",
            "It took 0.0032219886779785156 seconds to query forest.\n",
            "It took 0.00281524658203125 seconds to query forest.\n",
            "It took 0.0032720565795898438 seconds to query forest.\n",
            "It took 0.0031833648681640625 seconds to query forest.\n",
            "It took 0.003183126449584961 seconds to query forest.\n",
            "It took 0.0033271312713623047 seconds to query forest.\n",
            "It took 0.0033271312713623047 seconds to query forest.\n",
            "It took 0.003248453140258789 seconds to query forest.\n",
            "It took 0.003373384475708008 seconds to query forest.\n",
            "It took 0.0030710697174072266 seconds to query forest.\n",
            "It took 0.003498077392578125 seconds to query forest.\n",
            "It took 0.0029592514038085938 seconds to query forest.\n",
            "It took 0.002974271774291992 seconds to query forest.\n",
            "It took 0.004596233367919922 seconds to query forest.\n",
            "It took 0.0034875869750976562 seconds to query forest.\n",
            "It took 0.0029752254486083984 seconds to query forest.\n",
            "It took 0.00432586669921875 seconds to query forest.\n",
            "It took 0.004124641418457031 seconds to query forest.\n",
            "It took 0.003393888473510742 seconds to query forest.\n",
            "It took 0.003141164779663086 seconds to query forest.\n",
            "It took 0.0028200149536132812 seconds to query forest.\n",
            "It took 0.0035092830657958984 seconds to query forest.\n",
            "It took 0.0027103424072265625 seconds to query forest.\n",
            "It took 0.003213644027709961 seconds to query forest.\n",
            "It took 0.0033614635467529297 seconds to query forest.\n",
            "It took 0.0033402442932128906 seconds to query forest.\n",
            "It took 0.0034656524658203125 seconds to query forest.\n",
            "It took 0.0029845237731933594 seconds to query forest.\n",
            "It took 0.003429412841796875 seconds to query forest.\n",
            "It took 0.0030493736267089844 seconds to query forest.\n",
            "It took 0.0031402111053466797 seconds to query forest.\n",
            "It took 0.003909587860107422 seconds to query forest.\n",
            "It took 0.003216981887817383 seconds to query forest.\n",
            "It took 0.003065824508666992 seconds to query forest.\n",
            "It took 0.003574848175048828 seconds to query forest.\n",
            "It took 0.0036249160766601562 seconds to query forest.\n",
            "It took 0.0039048194885253906 seconds to query forest.\n",
            "It took 0.0030372142791748047 seconds to query forest.\n",
            "It took 0.0037708282470703125 seconds to query forest.\n",
            "It took 0.0029916763305664062 seconds to query forest.\n",
            "It took 0.0027320384979248047 seconds to query forest.\n",
            "It took 0.0032777786254882812 seconds to query forest.\n",
            "It took 0.0030579566955566406 seconds to query forest.\n",
            "It took 0.003595113754272461 seconds to query forest.\n",
            "It took 0.004156351089477539 seconds to query forest.\n",
            "It took 0.0029065608978271484 seconds to query forest.\n",
            "It took 0.0034027099609375 seconds to query forest.\n",
            "It took 0.0026540756225585938 seconds to query forest.\n",
            "It took 0.0038881301879882812 seconds to query forest.\n",
            "It took 0.0031452178955078125 seconds to query forest.\n",
            "It took 0.0028753280639648438 seconds to query forest.\n",
            "It took 0.0048940181732177734 seconds to query forest.\n",
            "It took 0.003185749053955078 seconds to query forest.\n",
            "It took 0.0032813549041748047 seconds to query forest.\n",
            "It took 0.0033354759216308594 seconds to query forest.\n",
            "It took 0.0038633346557617188 seconds to query forest.\n",
            "It took 0.0029561519622802734 seconds to query forest.\n",
            "It took 0.0030608177185058594 seconds to query forest.\n",
            "It took 0.00327301025390625 seconds to query forest.\n",
            "It took 0.003203153610229492 seconds to query forest.\n",
            "It took 0.00318145751953125 seconds to query forest.\n",
            "It took 0.003262758255004883 seconds to query forest.\n",
            "It took 0.003049612045288086 seconds to query forest.\n",
            "It took 0.003500699996948242 seconds to query forest.\n",
            "It took 0.003904581069946289 seconds to query forest.\n",
            "It took 0.004880666732788086 seconds to query forest.\n",
            "It took 0.0035102367401123047 seconds to query forest.\n",
            "It took 0.0028219223022460938 seconds to query forest.\n",
            "It took 0.0031044483184814453 seconds to query forest.\n",
            "It took 0.0032684803009033203 seconds to query forest.\n",
            "It took 0.0030989646911621094 seconds to query forest.\n",
            "It took 0.003462553024291992 seconds to query forest.\n",
            "It took 0.0034475326538085938 seconds to query forest.\n",
            "It took 0.003477811813354492 seconds to query forest.\n",
            "It took 0.0031778812408447266 seconds to query forest.\n",
            "It took 0.0028142929077148438 seconds to query forest.\n",
            "It took 0.0033478736877441406 seconds to query forest.\n",
            "It took 0.00341796875 seconds to query forest.\n",
            "It took 0.003924131393432617 seconds to query forest.\n",
            "It took 0.004591703414916992 seconds to query forest.\n",
            "It took 0.003420114517211914 seconds to query forest.\n",
            "It took 0.0031402111053466797 seconds to query forest.\n",
            "It took 0.003649473190307617 seconds to query forest.\n",
            "It took 0.0031096935272216797 seconds to query forest.\n",
            "It took 0.003060579299926758 seconds to query forest.\n",
            "It took 0.003534555435180664 seconds to query forest.\n",
            "It took 0.003767251968383789 seconds to query forest.\n",
            "It took 0.0032393932342529297 seconds to query forest.\n",
            "It took 0.0031578540802001953 seconds to query forest.\n",
            "It took 0.003446340560913086 seconds to query forest.\n",
            "It took 0.0030477046966552734 seconds to query forest.\n",
            "It took 0.003597259521484375 seconds to query forest.\n",
            "It took 0.0030384063720703125 seconds to query forest.\n",
            "It took 0.003796100616455078 seconds to query forest.\n",
            "It took 0.003454923629760742 seconds to query forest.\n",
            "It took 0.004505157470703125 seconds to query forest.\n",
            "It took 0.0033037662506103516 seconds to query forest.\n",
            "It took 0.0037093162536621094 seconds to query forest.\n",
            "It took 0.003085613250732422 seconds to query forest.\n",
            "It took 0.004669666290283203 seconds to query forest.\n",
            "It took 0.0033600330352783203 seconds to query forest.\n",
            "It took 0.0035827159881591797 seconds to query forest.\n",
            "It took 0.0029311180114746094 seconds to query forest.\n",
            "It took 0.004320383071899414 seconds to query forest.\n",
            "It took 0.0028862953186035156 seconds to query forest.\n",
            "It took 0.003256082534790039 seconds to query forest.\n",
            "It took 0.0032308101654052734 seconds to query forest.\n",
            "It took 0.003933429718017578 seconds to query forest.\n",
            "It took 0.0033524036407470703 seconds to query forest.\n",
            "It took 0.005368709564208984 seconds to query forest.\n",
            "It took 0.003324270248413086 seconds to query forest.\n",
            "It took 0.0035669803619384766 seconds to query forest.\n",
            "It took 0.003373861312866211 seconds to query forest.\n",
            "It took 0.003358125686645508 seconds to query forest.\n",
            "It took 0.003583192825317383 seconds to query forest.\n",
            "It took 0.0032846927642822266 seconds to query forest.\n",
            "It took 0.0032775402069091797 seconds to query forest.\n",
            "It took 0.003359079360961914 seconds to query forest.\n",
            "It took 0.0031130313873291016 seconds to query forest.\n",
            "It took 0.0033583641052246094 seconds to query forest.\n",
            "It took 0.0032732486724853516 seconds to query forest.\n",
            "It took 0.0033903121948242188 seconds to query forest.\n",
            "It took 0.0030050277709960938 seconds to query forest.\n",
            "It took 0.004008769989013672 seconds to query forest.\n",
            "It took 0.003351449966430664 seconds to query forest.\n",
            "It took 0.004658937454223633 seconds to query forest.\n",
            "It took 0.002981901168823242 seconds to query forest.\n",
            "It took 0.003180265426635742 seconds to query forest.\n",
            "It took 0.0031614303588867188 seconds to query forest.\n",
            "It took 0.003042936325073242 seconds to query forest.\n",
            "It took 0.004041433334350586 seconds to query forest.\n",
            "It took 0.003545045852661133 seconds to query forest.\n",
            "It took 0.003323793411254883 seconds to query forest.\n",
            "It took 0.0030722618103027344 seconds to query forest.\n",
            "It took 0.004096269607543945 seconds to query forest.\n",
            "It took 0.003560781478881836 seconds to query forest.\n",
            "It took 0.0028047561645507812 seconds to query forest.\n",
            "It took 0.005079984664916992 seconds to query forest.\n",
            "It took 0.0032851696014404297 seconds to query forest.\n",
            "It took 0.003238201141357422 seconds to query forest.\n",
            "It took 0.003283262252807617 seconds to query forest.\n",
            "It took 0.002967357635498047 seconds to query forest.\n",
            "It took 0.003390073776245117 seconds to query forest.\n",
            "It took 0.003078460693359375 seconds to query forest.\n",
            "It took 0.003220081329345703 seconds to query forest.\n",
            "It took 0.003683328628540039 seconds to query forest.\n",
            "It took 0.0028994083404541016 seconds to query forest.\n",
            "It took 0.003030538558959961 seconds to query forest.\n",
            "It took 0.003681182861328125 seconds to query forest.\n",
            "It took 0.0031015872955322266 seconds to query forest.\n",
            "It took 0.0031948089599609375 seconds to query forest.\n",
            "It took 0.0029447078704833984 seconds to query forest.\n",
            "It took 0.0031175613403320312 seconds to query forest.\n",
            "It took 0.003297090530395508 seconds to query forest.\n",
            "It took 0.005250692367553711 seconds to query forest.\n",
            "It took 0.004233837127685547 seconds to query forest.\n",
            "It took 0.004197359085083008 seconds to query forest.\n",
            "It took 0.0030317306518554688 seconds to query forest.\n",
            "It took 0.003045797348022461 seconds to query forest.\n",
            "It took 0.002833127975463867 seconds to query forest.\n",
            "It took 0.003641366958618164 seconds to query forest.\n",
            "It took 0.0030035972595214844 seconds to query forest.\n",
            "It took 0.002791166305541992 seconds to query forest.\n",
            "It took 0.003496408462524414 seconds to query forest.\n",
            "It took 0.0034661293029785156 seconds to query forest.\n",
            "It took 0.0033309459686279297 seconds to query forest.\n",
            "It took 0.0027844905853271484 seconds to query forest.\n",
            "It took 0.0030410289764404297 seconds to query forest.\n",
            "It took 0.003808259963989258 seconds to query forest.\n",
            "It took 0.003534555435180664 seconds to query forest.\n",
            "It took 0.003152132034301758 seconds to query forest.\n",
            "It took 0.0037937164306640625 seconds to query forest.\n",
            "It took 0.0032057762145996094 seconds to query forest.\n",
            "It took 0.003292083740234375 seconds to query forest.\n",
            "It took 0.005019664764404297 seconds to query forest.\n",
            "It took 0.0029213428497314453 seconds to query forest.\n",
            "It took 0.0030508041381835938 seconds to query forest.\n",
            "It took 0.004162311553955078 seconds to query forest.\n",
            "It took 0.002648591995239258 seconds to query forest.\n",
            "It took 0.0032126903533935547 seconds to query forest.\n",
            "It took 0.004005908966064453 seconds to query forest.\n",
            "It took 0.0035626888275146484 seconds to query forest.\n",
            "It took 0.0034377574920654297 seconds to query forest.\n",
            "It took 0.0033791065216064453 seconds to query forest.\n",
            "It took 0.0034513473510742188 seconds to query forest.\n",
            "It took 0.0035059452056884766 seconds to query forest.\n",
            "It took 0.003005504608154297 seconds to query forest.\n",
            "It took 0.002937793731689453 seconds to query forest.\n",
            "It took 0.0033707618713378906 seconds to query forest.\n",
            "It took 0.0035784244537353516 seconds to query forest.\n",
            "It took 0.002953767776489258 seconds to query forest.\n",
            "It took 0.0034682750701904297 seconds to query forest.\n",
            "It took 0.00286865234375 seconds to query forest.\n",
            "It took 0.003384828567504883 seconds to query forest.\n",
            "It took 0.0036911964416503906 seconds to query forest.\n",
            "It took 0.0030384063720703125 seconds to query forest.\n",
            "It took 0.003385305404663086 seconds to query forest.\n",
            "It took 0.0034308433532714844 seconds to query forest.\n",
            "It took 0.0033829212188720703 seconds to query forest.\n",
            "It took 0.005717754364013672 seconds to query forest.\n",
            "It took 0.004187107086181641 seconds to query forest.\n",
            "It took 0.0034852027893066406 seconds to query forest.\n",
            "It took 0.0036878585815429688 seconds to query forest.\n",
            "It took 0.003222227096557617 seconds to query forest.\n",
            "It took 0.003622770309448242 seconds to query forest.\n",
            "It took 0.004016399383544922 seconds to query forest.\n",
            "It took 0.00333404541015625 seconds to query forest.\n",
            "It took 0.003802776336669922 seconds to query forest.\n",
            "It took 0.0037260055541992188 seconds to query forest.\n",
            "It took 0.0037398338317871094 seconds to query forest.\n",
            "It took 0.003527402877807617 seconds to query forest.\n",
            "It took 0.003114461898803711 seconds to query forest.\n",
            "It took 0.004304647445678711 seconds to query forest.\n",
            "It took 0.0038111209869384766 seconds to query forest.\n",
            "It took 0.0031654834747314453 seconds to query forest.\n",
            "It took 0.003175973892211914 seconds to query forest.\n",
            "It took 0.003462553024291992 seconds to query forest.\n",
            "It took 0.003167867660522461 seconds to query forest.\n",
            "It took 0.003435373306274414 seconds to query forest.\n",
            "It took 0.0031032562255859375 seconds to query forest.\n",
            "It took 0.004209280014038086 seconds to query forest.\n",
            "It took 0.0045125484466552734 seconds to query forest.\n",
            "It took 0.003396749496459961 seconds to query forest.\n",
            "It took 0.0045053958892822266 seconds to query forest.\n",
            "It took 0.004162788391113281 seconds to query forest.\n",
            "It took 0.0032033920288085938 seconds to query forest.\n",
            "It took 0.002715587615966797 seconds to query forest.\n",
            "It took 0.0028829574584960938 seconds to query forest.\n",
            "It took 0.004268646240234375 seconds to query forest.\n",
            "It took 0.0031824111938476562 seconds to query forest.\n",
            "It took 0.0029747486114501953 seconds to query forest.\n",
            "It took 0.0032432079315185547 seconds to query forest.\n",
            "It took 0.0031435489654541016 seconds to query forest.\n",
            "It took 0.004868507385253906 seconds to query forest.\n",
            "It took 0.00366973876953125 seconds to query forest.\n",
            "It took 0.0040988922119140625 seconds to query forest.\n",
            "It took 0.003547191619873047 seconds to query forest.\n",
            "It took 0.002900362014770508 seconds to query forest.\n",
            "It took 0.003391742706298828 seconds to query forest.\n",
            "It took 0.003406047821044922 seconds to query forest.\n",
            "It took 0.0033245086669921875 seconds to query forest.\n",
            "It took 0.0033507347106933594 seconds to query forest.\n",
            "It took 0.003197193145751953 seconds to query forest.\n",
            "It took 0.003196239471435547 seconds to query forest.\n",
            "It took 0.0035486221313476562 seconds to query forest.\n",
            "It took 0.0038061141967773438 seconds to query forest.\n",
            "It took 0.003144502639770508 seconds to query forest.\n",
            "It took 0.003036022186279297 seconds to query forest.\n",
            "It took 0.003626108169555664 seconds to query forest.\n",
            "It took 0.003319263458251953 seconds to query forest.\n",
            "It took 0.0031266212463378906 seconds to query forest.\n",
            "It took 0.002718210220336914 seconds to query forest.\n",
            "It took 0.0030541419982910156 seconds to query forest.\n",
            "It took 0.005403995513916016 seconds to query forest.\n",
            "It took 0.004346132278442383 seconds to query forest.\n",
            "It took 0.003394603729248047 seconds to query forest.\n",
            "It took 0.003393888473510742 seconds to query forest.\n",
            "It took 0.002870321273803711 seconds to query forest.\n",
            "It took 0.004037618637084961 seconds to query forest.\n",
            "It took 0.004217386245727539 seconds to query forest.\n",
            "It took 0.0035948753356933594 seconds to query forest.\n",
            "It took 0.00368499755859375 seconds to query forest.\n",
            "It took 0.0033223628997802734 seconds to query forest.\n",
            "It took 0.0038564205169677734 seconds to query forest.\n",
            "It took 0.007102251052856445 seconds to query forest.\n",
            "It took 0.003199338912963867 seconds to query forest.\n",
            "It took 0.003359556198120117 seconds to query forest.\n",
            "It took 0.003516674041748047 seconds to query forest.\n",
            "It took 0.0026226043701171875 seconds to query forest.\n",
            "It took 0.0030410289764404297 seconds to query forest.\n",
            "It took 0.0031321048736572266 seconds to query forest.\n",
            "It took 0.0032639503479003906 seconds to query forest.\n",
            "It took 0.0033614635467529297 seconds to query forest.\n",
            "It took 0.0033435821533203125 seconds to query forest.\n",
            "It took 0.003481149673461914 seconds to query forest.\n",
            "It took 0.0028395652770996094 seconds to query forest.\n",
            "It took 0.0036885738372802734 seconds to query forest.\n",
            "It took 0.002924680709838867 seconds to query forest.\n",
            "It took 0.004759550094604492 seconds to query forest.\n",
            "It took 0.0031280517578125 seconds to query forest.\n",
            "It took 0.0030236244201660156 seconds to query forest.\n",
            "It took 0.005743265151977539 seconds to query forest.\n",
            "It took 0.0034825801849365234 seconds to query forest.\n",
            "It took 0.0032355785369873047 seconds to query forest.\n",
            "It took 0.0032329559326171875 seconds to query forest.\n",
            "It took 0.0035338401794433594 seconds to query forest.\n",
            "It took 0.0033333301544189453 seconds to query forest.\n",
            "It took 0.003346681594848633 seconds to query forest.\n",
            "It took 0.0041086673736572266 seconds to query forest.\n",
            "It took 0.003042936325073242 seconds to query forest.\n",
            "It took 0.0037488937377929688 seconds to query forest.\n",
            "It took 0.003977537155151367 seconds to query forest.\n",
            "It took 0.003560781478881836 seconds to query forest.\n",
            "It took 0.0034520626068115234 seconds to query forest.\n",
            "It took 0.002819061279296875 seconds to query forest.\n",
            "It took 0.003324747085571289 seconds to query forest.\n",
            "It took 0.003107786178588867 seconds to query forest.\n",
            "It took 0.0031273365020751953 seconds to query forest.\n",
            "It took 0.0031785964965820312 seconds to query forest.\n",
            "It took 0.0037953853607177734 seconds to query forest.\n",
            "It took 0.003618478775024414 seconds to query forest.\n",
            "It took 0.003865480422973633 seconds to query forest.\n",
            "It took 0.003579854965209961 seconds to query forest.\n",
            "It took 0.00313568115234375 seconds to query forest.\n",
            "It took 0.0031867027282714844 seconds to query forest.\n",
            "It took 0.003529071807861328 seconds to query forest.\n",
            "It took 0.003905773162841797 seconds to query forest.\n",
            "It took 0.0038971900939941406 seconds to query forest.\n",
            "It took 0.0033380985260009766 seconds to query forest.\n",
            "It took 0.0034029483795166016 seconds to query forest.\n",
            "It took 0.0033447742462158203 seconds to query forest.\n",
            "It took 0.003039836883544922 seconds to query forest.\n",
            "It took 0.003404378890991211 seconds to query forest.\n",
            "It took 0.0045506954193115234 seconds to query forest.\n",
            "It took 0.003615140914916992 seconds to query forest.\n",
            "It took 0.0034036636352539062 seconds to query forest.\n",
            "It took 0.00299072265625 seconds to query forest.\n",
            "It took 0.0033071041107177734 seconds to query forest.\n",
            "It took 0.0035581588745117188 seconds to query forest.\n",
            "It took 0.003371000289916992 seconds to query forest.\n",
            "It took 0.0030510425567626953 seconds to query forest.\n",
            "It took 0.0031197071075439453 seconds to query forest.\n",
            "It took 0.00313568115234375 seconds to query forest.\n",
            "It took 0.0046422481536865234 seconds to query forest.\n",
            "It took 0.0035712718963623047 seconds to query forest.\n",
            "It took 0.0029790401458740234 seconds to query forest.\n",
            "It took 0.004032611846923828 seconds to query forest.\n",
            "It took 0.0029463768005371094 seconds to query forest.\n",
            "It took 0.003798246383666992 seconds to query forest.\n",
            "It took 0.005101680755615234 seconds to query forest.\n",
            "It took 0.0031137466430664062 seconds to query forest.\n",
            "It took 0.0038597583770751953 seconds to query forest.\n",
            "It took 0.0037946701049804688 seconds to query forest.\n",
            "It took 0.003220796585083008 seconds to query forest.\n",
            "It took 0.003016233444213867 seconds to query forest.\n",
            "It took 0.0031027793884277344 seconds to query forest.\n",
            "It took 0.003514528274536133 seconds to query forest.\n",
            "It took 0.0034825801849365234 seconds to query forest.\n",
            "It took 0.004025459289550781 seconds to query forest.\n",
            "It took 0.004094123840332031 seconds to query forest.\n",
            "It took 0.0031213760375976562 seconds to query forest.\n",
            "It took 0.0035140514373779297 seconds to query forest.\n",
            "It took 0.0033309459686279297 seconds to query forest.\n",
            "It took 0.00482177734375 seconds to query forest.\n",
            "It took 0.0025358200073242188 seconds to query forest.\n",
            "It took 0.0029799938201904297 seconds to query forest.\n",
            "It took 0.003168344497680664 seconds to query forest.\n",
            "It took 0.0034062862396240234 seconds to query forest.\n",
            "It took 0.0030858516693115234 seconds to query forest.\n",
            "It took 0.0036318302154541016 seconds to query forest.\n",
            "It took 0.0033655166625976562 seconds to query forest.\n",
            "It took 0.003776073455810547 seconds to query forest.\n",
            "It took 0.0032591819763183594 seconds to query forest.\n",
            "It took 0.004326820373535156 seconds to query forest.\n",
            "It took 0.0033295154571533203 seconds to query forest.\n",
            "It took 0.002920389175415039 seconds to query forest.\n",
            "It took 0.004078388214111328 seconds to query forest.\n",
            "It took 0.003537416458129883 seconds to query forest.\n",
            "It took 0.0027573108673095703 seconds to query forest.\n",
            "It took 0.00413203239440918 seconds to query forest.\n",
            "It took 0.003743886947631836 seconds to query forest.\n",
            "It took 0.003523111343383789 seconds to query forest.\n",
            "It took 0.002954244613647461 seconds to query forest.\n",
            "It took 0.004974365234375 seconds to query forest.\n",
            "It took 0.0031397342681884766 seconds to query forest.\n",
            "It took 0.0038089752197265625 seconds to query forest.\n",
            "It took 0.00308990478515625 seconds to query forest.\n",
            "It took 0.0034193992614746094 seconds to query forest.\n",
            "It took 0.0035943984985351562 seconds to query forest.\n",
            "It took 0.0037734508514404297 seconds to query forest.\n",
            "It took 0.0029561519622802734 seconds to query forest.\n",
            "It took 0.0035398006439208984 seconds to query forest.\n",
            "It took 0.003610849380493164 seconds to query forest.\n",
            "It took 0.004744291305541992 seconds to query forest.\n",
            "It took 0.0048182010650634766 seconds to query forest.\n",
            "It took 0.0033483505249023438 seconds to query forest.\n",
            "It took 0.0037250518798828125 seconds to query forest.\n",
            "It took 0.003567218780517578 seconds to query forest.\n",
            "It took 0.0035266876220703125 seconds to query forest.\n",
            "It took 0.0039217472076416016 seconds to query forest.\n",
            "It took 0.0035486221313476562 seconds to query forest.\n",
            "It took 0.0032303333282470703 seconds to query forest.\n",
            "It took 0.0035390853881835938 seconds to query forest.\n",
            "It took 0.0032091140747070312 seconds to query forest.\n",
            "It took 0.003387451171875 seconds to query forest.\n",
            "It took 0.00399470329284668 seconds to query forest.\n",
            "It took 0.0037598609924316406 seconds to query forest.\n",
            "It took 0.003575563430786133 seconds to query forest.\n",
            "It took 0.0038847923278808594 seconds to query forest.\n",
            "It took 0.0034265518188476562 seconds to query forest.\n",
            "It took 0.003645181655883789 seconds to query forest.\n",
            "It took 0.003478527069091797 seconds to query forest.\n",
            "It took 0.003061056137084961 seconds to query forest.\n",
            "It took 0.0035517215728759766 seconds to query forest.\n",
            "It took 0.0038657188415527344 seconds to query forest.\n",
            "It took 0.003415822982788086 seconds to query forest.\n",
            "It took 0.003310680389404297 seconds to query forest.\n",
            "It took 0.004824399948120117 seconds to query forest.\n",
            "It took 0.00386810302734375 seconds to query forest.\n",
            "It took 0.003382444381713867 seconds to query forest.\n",
            "It took 0.003754854202270508 seconds to query forest.\n",
            "It took 0.003283262252807617 seconds to query forest.\n",
            "It took 0.003384113311767578 seconds to query forest.\n",
            "It took 0.0035774707794189453 seconds to query forest.\n",
            "It took 0.0031402111053466797 seconds to query forest.\n",
            "It took 0.003895282745361328 seconds to query forest.\n",
            "It took 0.0028243064880371094 seconds to query forest.\n",
            "It took 0.004683256149291992 seconds to query forest.\n",
            "It took 0.003646373748779297 seconds to query forest.\n",
            "It took 0.004354238510131836 seconds to query forest.\n",
            "It took 0.004647731781005859 seconds to query forest.\n",
            "It took 0.004975557327270508 seconds to query forest.\n",
            "It took 0.006811380386352539 seconds to query forest.\n",
            "It took 0.0034782886505126953 seconds to query forest.\n",
            "It took 0.0035674571990966797 seconds to query forest.\n",
            "It took 0.0032062530517578125 seconds to query forest.\n",
            "It took 0.0030570030212402344 seconds to query forest.\n",
            "It took 0.0035152435302734375 seconds to query forest.\n",
            "It took 0.003050565719604492 seconds to query forest.\n",
            "It took 0.003283262252807617 seconds to query forest.\n",
            "It took 0.0036182403564453125 seconds to query forest.\n",
            "It took 0.0030193328857421875 seconds to query forest.\n",
            "It took 0.0029506683349609375 seconds to query forest.\n",
            "It took 0.003087759017944336 seconds to query forest.\n",
            "It took 0.0034749507904052734 seconds to query forest.\n",
            "It took 0.003554821014404297 seconds to query forest.\n",
            "It took 0.0026655197143554688 seconds to query forest.\n",
            "It took 0.00538945198059082 seconds to query forest.\n",
            "It took 0.003068208694458008 seconds to query forest.\n",
            "It took 0.0036911964416503906 seconds to query forest.\n",
            "It took 0.003607511520385742 seconds to query forest.\n",
            "It took 0.003133058547973633 seconds to query forest.\n",
            "It took 0.0032134056091308594 seconds to query forest.\n",
            "It took 0.00407099723815918 seconds to query forest.\n",
            "It took 0.003267049789428711 seconds to query forest.\n",
            "It took 0.0032057762145996094 seconds to query forest.\n",
            "It took 0.0030622482299804688 seconds to query forest.\n",
            "It took 0.003772735595703125 seconds to query forest.\n",
            "It took 0.004652738571166992 seconds to query forest.\n",
            "It took 0.0045778751373291016 seconds to query forest.\n",
            "It took 0.003408670425415039 seconds to query forest.\n",
            "It took 0.005301237106323242 seconds to query forest.\n",
            "It took 0.003672361373901367 seconds to query forest.\n",
            "It took 0.003999948501586914 seconds to query forest.\n",
            "It took 0.003441333770751953 seconds to query forest.\n",
            "It took 0.002897024154663086 seconds to query forest.\n",
            "It took 0.0049855709075927734 seconds to query forest.\n",
            "It took 0.003015279769897461 seconds to query forest.\n",
            "It took 0.0029141902923583984 seconds to query forest.\n",
            "It took 0.0033104419708251953 seconds to query forest.\n",
            "It took 0.0030639171600341797 seconds to query forest.\n",
            "It took 0.005367755889892578 seconds to query forest.\n",
            "It took 0.002730846405029297 seconds to query forest.\n",
            "It took 0.003410816192626953 seconds to query forest.\n",
            "It took 0.0035758018493652344 seconds to query forest.\n",
            "It took 0.0029261112213134766 seconds to query forest.\n",
            "It took 0.0035254955291748047 seconds to query forest.\n",
            "It took 0.004297494888305664 seconds to query forest.\n",
            "It took 0.003861665725708008 seconds to query forest.\n",
            "It took 0.0039365291595458984 seconds to query forest.\n",
            "It took 0.0033578872680664062 seconds to query forest.\n",
            "It took 0.0033829212188720703 seconds to query forest.\n",
            "It took 0.003710031509399414 seconds to query forest.\n",
            "It took 0.0034291744232177734 seconds to query forest.\n",
            "It took 0.0046672821044921875 seconds to query forest.\n",
            "It took 0.003441333770751953 seconds to query forest.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[           Category  ... cat\n",
              " 5355     Technology  ...   2\n",
              " 4212     Technology  ...   2\n",
              " 5801  Entertainment  ...   3\n",
              " 5805  Entertainment  ...   3\n",
              " 448          Sports  ...   0\n",
              " 1664         Sports  ...   0\n",
              " 5393     Technology  ...   2\n",
              " 5629     Technology  ...   2\n",
              " 5733  Entertainment  ...   3\n",
              " 5735  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 1297         Sports  ...   0\n",
              " 2131         Sports  ...   0\n",
              " 5789  Entertainment  ...   3\n",
              " 5799  Entertainment  ...   3\n",
              " 5830  Entertainment  ...   3\n",
              " 5279     Technology  ...   2\n",
              " 2961       Business  ...   1\n",
              " 2996       Business  ...   1\n",
              " 5081     Technology  ...   2\n",
              " 5175     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5811  Entertainment  ...   3\n",
              " 5839  Entertainment  ...   3\n",
              " 3730       Business  ...   1\n",
              " 4397     Technology  ...   2\n",
              " 5867  Entertainment  ...   3\n",
              " 5878  Entertainment  ...   3\n",
              " 5865  Entertainment  ...   3\n",
              " 5686  Entertainment  ...   3\n",
              " 347          Sports  ...   0\n",
              " 2862       Business  ...   1\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 1562         Sports  ...   0\n",
              " 1644         Sports  ...   0\n",
              " 5357     Technology  ...   2\n",
              " 5309     Technology  ...   2\n",
              " 693          Sports  ...   0\n",
              " 5878  Entertainment  ...   3\n",
              " 5922  Entertainment  ...   3\n",
              " 5910  Entertainment  ...   3\n",
              " 3164       Business  ...   1\n",
              " 645          Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 3257       Business  ...   1\n",
              " 3198       Business  ...   1\n",
              " 2693       Business  ...   1\n",
              " 2399       Business  ...   1\n",
              " 5851  Entertainment  ...   3\n",
              " 5846  Entertainment  ...   3\n",
              " 2577       Business  ...   1\n",
              " 2447       Business  ...   1\n",
              " 2545       Business  ...   1\n",
              " 2388       Business  ...   1\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 4925     Technology  ...   2\n",
              " 4775     Technology  ...   2\n",
              " 481          Sports  ...   0\n",
              " 463          Sports  ...   0\n",
              " 5833  Entertainment  ...   3\n",
              " 5830  Entertainment  ...   3\n",
              " 5085     Technology  ...   2\n",
              " 5878  Entertainment  ...   3\n",
              " 166          Sports  ...   0\n",
              " 214          Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 352          Sports  ...   0\n",
              " 341          Sports  ...   0\n",
              " 5714  Entertainment  ...   3\n",
              " 5708  Entertainment  ...   3\n",
              " 3866       Business  ...   1\n",
              " 3874       Business  ...   1\n",
              " 5612     Technology  ...   2\n",
              " 5861  Entertainment  ...   3\n",
              " 2729       Business  ...   1\n",
              " 3434       Business  ...   1\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5241     Technology  ...   2\n",
              " 718          Sports  ...   0\n",
              " 5761  Entertainment  ...   3\n",
              " 5756  Entertainment  ...   3\n",
              " 4496     Technology  ...   2\n",
              " 4734     Technology  ...   2\n",
              " 2385       Business  ...   1\n",
              " 817          Sports  ...   0\n",
              " 5530     Technology  ...   2\n",
              " 4862     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],         Category  ... cat\n",
              " 1306      Sports  ...   0\n",
              " 555       Sports  ...   0\n",
              " 4954  Technology  ...   2\n",
              " 4851  Technology  ...   2\n",
              " 5566  Technology  ...   2\n",
              " 5623  Technology  ...   2\n",
              " 4225  Technology  ...   2\n",
              " 282       Sports  ...   0\n",
              " 305       Sports  ...   0\n",
              " 301       Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 2800       Business  ...   1\n",
              " 3230       Business  ...   1\n",
              " 2792       Business  ...   1\n",
              " 2751       Business  ...   1\n",
              " 763          Sports  ...   0\n",
              " 790          Sports  ...   0\n",
              " 558          Sports  ...   0\n",
              " 5230     Technology  ...   2\n",
              " 5750  Entertainment  ...   3\n",
              " 5751  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 2220         Sports  ...   0\n",
              " 860          Sports  ...   0\n",
              " 3378       Business  ...   1\n",
              " 3388       Business  ...   1\n",
              " 5316     Technology  ...   2\n",
              " 5871  Entertainment  ...   3\n",
              " 4344     Technology  ...   2\n",
              " 5635     Technology  ...   2\n",
              " 4777     Technology  ...   2\n",
              " 555          Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5553     Technology  ...   2\n",
              " 5388     Technology  ...   2\n",
              " 5872  Entertainment  ...   3\n",
              " 5844  Entertainment  ...   3\n",
              " 4883     Technology  ...   2\n",
              " 4252     Technology  ...   2\n",
              " 4376     Technology  ...   2\n",
              " 3115       Business  ...   1\n",
              " 2514       Business  ...   1\n",
              " 1443         Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 3564       Business  ...   1\n",
              " 3622       Business  ...   1\n",
              " 773          Sports  ...   0\n",
              " 2903       Business  ...   1\n",
              " 2483       Business  ...   1\n",
              " 2501       Business  ...   1\n",
              " 5922  Entertainment  ...   3\n",
              " 5910  Entertainment  ...   3\n",
              " 9            Sports  ...   0\n",
              " 3338       Business  ...   1\n",
              " \n",
              " [10 rows x 7 columns],         Category  ... cat\n",
              " 4443  Technology  ...   2\n",
              " 4406  Technology  ...   2\n",
              " 1084      Sports  ...   0\n",
              " 5253  Technology  ...   2\n",
              " 1699      Sports  ...   0\n",
              " 1703      Sports  ...   0\n",
              " 3409    Business  ...   1\n",
              " 1610      Sports  ...   0\n",
              " 4408  Technology  ...   2\n",
              " 1587      Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5867  Entertainment  ...   3\n",
              " 5878  Entertainment  ...   3\n",
              " 5422     Technology  ...   2\n",
              " 4359     Technology  ...   2\n",
              " 232          Sports  ...   0\n",
              " 5874  Entertainment  ...   3\n",
              " 5604     Technology  ...   2\n",
              " 4828     Technology  ...   2\n",
              " 3841       Business  ...   1\n",
              " 3947       Business  ...   1\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 4920     Technology  ...   2\n",
              " 3129       Business  ...   1\n",
              " 5801  Entertainment  ...   3\n",
              " 5775  Entertainment  ...   3\n",
              " 684          Sports  ...   0\n",
              " 13           Sports  ...   0\n",
              " 5355     Technology  ...   2\n",
              " 4212     Technology  ...   2\n",
              " 3192       Business  ...   1\n",
              " 4393     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5740  Entertainment  ...   3\n",
              " 5741  Entertainment  ...   3\n",
              " 5696  Entertainment  ...   3\n",
              " 5698  Entertainment  ...   3\n",
              " 5417     Technology  ...   2\n",
              " 5054     Technology  ...   2\n",
              " 5451     Technology  ...   2\n",
              " 5619     Technology  ...   2\n",
              " 4713     Technology  ...   2\n",
              " 4314     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5356     Technology  ...   2\n",
              " 4838     Technology  ...   2\n",
              " 4044       Business  ...   1\n",
              " 3054       Business  ...   1\n",
              " 1545         Sports  ...   0\n",
              " 1639         Sports  ...   0\n",
              " 5897  Entertainment  ...   3\n",
              " 5890  Entertainment  ...   3\n",
              " 5867  Entertainment  ...   3\n",
              " 5878  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5224     Technology  ...   2\n",
              " 5179     Technology  ...   2\n",
              " 3321       Business  ...   1\n",
              " 3215       Business  ...   1\n",
              " 1699         Sports  ...   0\n",
              " 1703         Sports  ...   0\n",
              " 5867  Entertainment  ...   3\n",
              " 5878  Entertainment  ...   3\n",
              " 5811  Entertainment  ...   3\n",
              " 5839  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 4161     Technology  ...   2\n",
              " 4135     Technology  ...   2\n",
              " 5734  Entertainment  ...   3\n",
              " 5686  Entertainment  ...   3\n",
              " 5144     Technology  ...   2\n",
              " 5086     Technology  ...   2\n",
              " 522          Sports  ...   0\n",
              " 335          Sports  ...   0\n",
              " 5851  Entertainment  ...   3\n",
              " 5846  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5900  Entertainment  ...   3\n",
              " 5774  Entertainment  ...   3\n",
              " 2449       Business  ...   1\n",
              " 5467     Technology  ...   2\n",
              " 2923       Business  ...   1\n",
              " 4342     Technology  ...   2\n",
              " 3750       Business  ...   1\n",
              " 5831  Entertainment  ...   3\n",
              " 5833  Entertainment  ...   3\n",
              " 5830  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5745  Entertainment  ...   3\n",
              " 5741  Entertainment  ...   3\n",
              " 5009     Technology  ...   2\n",
              " 2599       Business  ...   1\n",
              " 4724     Technology  ...   2\n",
              " 4972     Technology  ...   2\n",
              " 1775         Sports  ...   0\n",
              " 4383     Technology  ...   2\n",
              " 614          Sports  ...   0\n",
              " 510          Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 1265         Sports  ...   0\n",
              " 5874  Entertainment  ...   3\n",
              " 4940     Technology  ...   2\n",
              " 4949     Technology  ...   2\n",
              " 5897  Entertainment  ...   3\n",
              " 5890  Entertainment  ...   3\n",
              " 3475       Business  ...   1\n",
              " 1254         Sports  ...   0\n",
              " 5713  Entertainment  ...   3\n",
              " 5714  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],         Category  ... cat\n",
              " 5381  Technology  ...   2\n",
              " 4991  Technology  ...   2\n",
              " 5041  Technology  ...   2\n",
              " 4125  Technology  ...   2\n",
              " 5627  Technology  ...   2\n",
              " 4230  Technology  ...   2\n",
              " 5178  Technology  ...   2\n",
              " 5165  Technology  ...   2\n",
              " 5210  Technology  ...   2\n",
              " 5055  Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 1601         Sports  ...   0\n",
              " 1610         Sports  ...   0\n",
              " 5728  Entertainment  ...   3\n",
              " 5878  Entertainment  ...   3\n",
              " 5820  Entertainment  ...   3\n",
              " 5837  Entertainment  ...   3\n",
              " 5290     Technology  ...   2\n",
              " 495          Sports  ...   0\n",
              " 1354         Sports  ...   0\n",
              " 5295     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 73           Sports  ...   0\n",
              " 69           Sports  ...   0\n",
              " 2170         Sports  ...   0\n",
              " 2174         Sports  ...   0\n",
              " 3653       Business  ...   1\n",
              " 5878  Entertainment  ...   3\n",
              " 5109     Technology  ...   2\n",
              " 3191       Business  ...   1\n",
              " 2102         Sports  ...   0\n",
              " 1527         Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],         Category  ... cat\n",
              " 4252  Technology  ...   2\n",
              " 4143  Technology  ...   2\n",
              " 3308    Business  ...   1\n",
              " 2990    Business  ...   1\n",
              " 484       Sports  ...   0\n",
              " 1046      Sports  ...   0\n",
              " 2866    Business  ...   1\n",
              " 4063    Business  ...   1\n",
              " 329       Sports  ...   0\n",
              " 134       Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 2189         Sports  ...   0\n",
              " 4350     Technology  ...   2\n",
              " 5897  Entertainment  ...   3\n",
              " 5890  Entertainment  ...   3\n",
              " 5045     Technology  ...   2\n",
              " 4910     Technology  ...   2\n",
              " 5913  Entertainment  ...   3\n",
              " 5894  Entertainment  ...   3\n",
              " 5813  Entertainment  ...   3\n",
              " 5071     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5848  Entertainment  ...   3\n",
              " 5853  Entertainment  ...   3\n",
              " 922          Sports  ...   0\n",
              " 1254         Sports  ...   0\n",
              " 5835  Entertainment  ...   3\n",
              " 5839  Entertainment  ...   3\n",
              " 5636     Technology  ...   2\n",
              " 4565     Technology  ...   2\n",
              " 5874  Entertainment  ...   3\n",
              " 5830  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 506          Sports  ...   0\n",
              " 493          Sports  ...   0\n",
              " 5734  Entertainment  ...   3\n",
              " 5719  Entertainment  ...   3\n",
              " 5897  Entertainment  ...   3\n",
              " 5806  Entertainment  ...   3\n",
              " 5730  Entertainment  ...   3\n",
              " 1107         Sports  ...   0\n",
              " 5587     Technology  ...   2\n",
              " 5558     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 4362     Technology  ...   2\n",
              " 4895     Technology  ...   2\n",
              " 4233     Technology  ...   2\n",
              " 4292     Technology  ...   2\n",
              " 5900  Entertainment  ...   3\n",
              " 5774  Entertainment  ...   3\n",
              " 513          Sports  ...   0\n",
              " 468          Sports  ...   0\n",
              " 5810  Entertainment  ...   3\n",
              " 5839  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5168     Technology  ...   2\n",
              " 5176     Technology  ...   2\n",
              " 5760  Entertainment  ...   3\n",
              " 5878  Entertainment  ...   3\n",
              " 2230         Sports  ...   0\n",
              " 1967         Sports  ...   0\n",
              " 956          Sports  ...   0\n",
              " 3333       Business  ...   1\n",
              " 2444       Business  ...   1\n",
              " 3164       Business  ...   1\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5785  Entertainment  ...   3\n",
              " 5677     Technology  ...   2\n",
              " 2025         Sports  ...   0\n",
              " 1331         Sports  ...   0\n",
              " 3642       Business  ...   1\n",
              " 3755       Business  ...   1\n",
              " 1568         Sports  ...   0\n",
              " 3004       Business  ...   1\n",
              " 4313     Technology  ...   2\n",
              " 4331     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5757  Entertainment  ...   3\n",
              " 5759  Entertainment  ...   3\n",
              " 1260         Sports  ...   0\n",
              " 1103         Sports  ...   0\n",
              " 3961       Business  ...   1\n",
              " 5204     Technology  ...   2\n",
              " 5884  Entertainment  ...   3\n",
              " 4477     Technology  ...   2\n",
              " 5497     Technology  ...   2\n",
              " 5475     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 3134       Business  ...   1\n",
              " 3158       Business  ...   1\n",
              " 5763  Entertainment  ...   3\n",
              " 5774  Entertainment  ...   3\n",
              " 5721  Entertainment  ...   3\n",
              " 5719  Entertainment  ...   3\n",
              " 2954       Business  ...   1\n",
              " 5518     Technology  ...   2\n",
              " 3826       Business  ...   1\n",
              " 38           Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 2681       Business  ...   1\n",
              " 2598       Business  ...   1\n",
              " 5472     Technology  ...   2\n",
              " 5512     Technology  ...   2\n",
              " 4272     Technology  ...   2\n",
              " 4601     Technology  ...   2\n",
              " 5914  Entertainment  ...   3\n",
              " 5919  Entertainment  ...   3\n",
              " 5900  Entertainment  ...   3\n",
              " 5774  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 3494       Business  ...   1\n",
              " 3662       Business  ...   1\n",
              " 5900  Entertainment  ...   3\n",
              " 5774  Entertainment  ...   3\n",
              " 5912  Entertainment  ...   3\n",
              " 5910  Entertainment  ...   3\n",
              " 672          Sports  ...   0\n",
              " 1168         Sports  ...   0\n",
              " 2888       Business  ...   1\n",
              " 3826       Business  ...   1\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5878  Entertainment  ...   3\n",
              " 5863  Entertainment  ...   3\n",
              " 5563     Technology  ...   2\n",
              " 5477     Technology  ...   2\n",
              " 1793         Sports  ...   0\n",
              " 5530     Technology  ...   2\n",
              " 1058         Sports  ...   0\n",
              " 167          Sports  ...   0\n",
              " 4912     Technology  ...   2\n",
              " 5716  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 1491         Sports  ...   0\n",
              " 1691         Sports  ...   0\n",
              " 3946       Business  ...   1\n",
              " 5620     Technology  ...   2\n",
              " 2621       Business  ...   1\n",
              " 2767       Business  ...   1\n",
              " 1156         Sports  ...   0\n",
              " 5790  Entertainment  ...   3\n",
              " 5745  Entertainment  ...   3\n",
              " 5741  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5833  Entertainment  ...   3\n",
              " 5830  Entertainment  ...   3\n",
              " 5024     Technology  ...   2\n",
              " 5021     Technology  ...   2\n",
              " 1276         Sports  ...   0\n",
              " 4583     Technology  ...   2\n",
              " 5714  Entertainment  ...   3\n",
              " 3245       Business  ...   1\n",
              " 2480       Business  ...   1\n",
              " 2398       Business  ...   1\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 152          Sports  ...   0\n",
              " 18           Sports  ...   0\n",
              " 5867  Entertainment  ...   3\n",
              " 5852  Entertainment  ...   3\n",
              " 3415       Business  ...   1\n",
              " 5007     Technology  ...   2\n",
              " 1264         Sports  ...   0\n",
              " 3952       Business  ...   1\n",
              " 5796  Entertainment  ...   3\n",
              " 5830  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5808  Entertainment  ...   3\n",
              " 5417     Technology  ...   2\n",
              " 1003         Sports  ...   0\n",
              " 909          Sports  ...   0\n",
              " 466          Sports  ...   0\n",
              " 478          Sports  ...   0\n",
              " 3040       Business  ...   1\n",
              " 2361         Sports  ...   0\n",
              " 4690     Technology  ...   2\n",
              " 4567     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5733  Entertainment  ...   3\n",
              " 5735  Entertainment  ...   3\n",
              " 4697     Technology  ...   2\n",
              " 4094       Business  ...   1\n",
              " 1993         Sports  ...   0\n",
              " 2001         Sports  ...   0\n",
              " 2823       Business  ...   1\n",
              " 4239     Technology  ...   2\n",
              " 352          Sports  ...   0\n",
              " 341          Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5770  Entertainment  ...   3\n",
              " 2763       Business  ...   1\n",
              " 5867  Entertainment  ...   3\n",
              " 5878  Entertainment  ...   3\n",
              " 5057     Technology  ...   2\n",
              " 4714     Technology  ...   2\n",
              " 5833  Entertainment  ...   3\n",
              " 5830  Entertainment  ...   3\n",
              " 5546     Technology  ...   2\n",
              " 4509     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 4502     Technology  ...   2\n",
              " 5622     Technology  ...   2\n",
              " 3137       Business  ...   1\n",
              " 3129       Business  ...   1\n",
              " 5808  Entertainment  ...   3\n",
              " 5417     Technology  ...   2\n",
              " 3201       Business  ...   1\n",
              " 1100         Sports  ...   0\n",
              " 4844     Technology  ...   2\n",
              " 4774     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 3341       Business  ...   1\n",
              " 2095         Sports  ...   0\n",
              " 1798         Sports  ...   0\n",
              " 4799     Technology  ...   2\n",
              " 5712  Entertainment  ...   3\n",
              " 5417     Technology  ...   2\n",
              " 1107         Sports  ...   0\n",
              " 3638       Business  ...   1\n",
              " 5833  Entertainment  ...   3\n",
              " 5830  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 1432         Sports  ...   0\n",
              " 2911       Business  ...   1\n",
              " 5713  Entertainment  ...   3\n",
              " 5714  Entertainment  ...   3\n",
              " 5690  Entertainment  ...   3\n",
              " 5790  Entertainment  ...   3\n",
              " 4177     Technology  ...   2\n",
              " 4462     Technology  ...   2\n",
              " 2342         Sports  ...   0\n",
              " 2215         Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5200     Technology  ...   2\n",
              " 2547       Business  ...   1\n",
              " 5873  Entertainment  ...   3\n",
              " 5085     Technology  ...   2\n",
              " 5867  Entertainment  ...   3\n",
              " 5852  Entertainment  ...   3\n",
              " 1002         Sports  ...   0\n",
              " 549          Sports  ...   0\n",
              " 932          Sports  ...   0\n",
              " 5223     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 3437       Business  ...   1\n",
              " 3503       Business  ...   1\n",
              " 5818  Entertainment  ...   3\n",
              " 4863     Technology  ...   2\n",
              " 5612     Technology  ...   2\n",
              " 5807  Entertainment  ...   3\n",
              " 5904  Entertainment  ...   3\n",
              " 5878  Entertainment  ...   3\n",
              " 5592     Technology  ...   2\n",
              " 5525     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5754  Entertainment  ...   3\n",
              " 5076     Technology  ...   2\n",
              " 896          Sports  ...   0\n",
              " 5082     Technology  ...   2\n",
              " 4197     Technology  ...   2\n",
              " 4261     Technology  ...   2\n",
              " 3201       Business  ...   1\n",
              " 5814  Entertainment  ...   3\n",
              " 3715       Business  ...   1\n",
              " 1725         Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5713  Entertainment  ...   3\n",
              " 5714  Entertainment  ...   3\n",
              " 2987       Business  ...   1\n",
              " 3054       Business  ...   1\n",
              " 1713         Sports  ...   0\n",
              " 1370         Sports  ...   0\n",
              " 4036       Business  ...   1\n",
              " 3254       Business  ...   1\n",
              " 988          Sports  ...   0\n",
              " 991          Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5714  Entertainment  ...   3\n",
              " 5332     Technology  ...   2\n",
              " 4473     Technology  ...   2\n",
              " 1244         Sports  ...   0\n",
              " 5867  Entertainment  ...   3\n",
              " 5878  Entertainment  ...   3\n",
              " 4857     Technology  ...   2\n",
              " 3210       Business  ...   1\n",
              " 5912  Entertainment  ...   3\n",
              " 5910  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 220          Sports  ...   0\n",
              " 238          Sports  ...   0\n",
              " 5754  Entertainment  ...   3\n",
              " 5877  Entertainment  ...   3\n",
              " 3538       Business  ...   1\n",
              " 3563       Business  ...   1\n",
              " 5820  Entertainment  ...   3\n",
              " 5823  Entertainment  ...   3\n",
              " 5824  Entertainment  ...   3\n",
              " 5839  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 961          Sports  ...   0\n",
              " 757          Sports  ...   0\n",
              " 2668       Business  ...   1\n",
              " 3767       Business  ...   1\n",
              " 5062     Technology  ...   2\n",
              " 3111       Business  ...   1\n",
              " 4824     Technology  ...   2\n",
              " 4932     Technology  ...   2\n",
              " 2298         Sports  ...   0\n",
              " 5741  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 2256         Sports  ...   0\n",
              " 3366       Business  ...   1\n",
              " 5878  Entertainment  ...   3\n",
              " 5790  Entertainment  ...   3\n",
              " 1304         Sports  ...   0\n",
              " 1293         Sports  ...   0\n",
              " 2405       Business  ...   1\n",
              " 5741  Entertainment  ...   3\n",
              " 2212         Sports  ...   0\n",
              " 2111         Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 2098         Sports  ...   0\n",
              " 5900  Entertainment  ...   3\n",
              " 5720  Entertainment  ...   3\n",
              " 1089         Sports  ...   0\n",
              " 2131         Sports  ...   0\n",
              " 5803  Entertainment  ...   3\n",
              " 5825  Entertainment  ...   3\n",
              " 5828  Entertainment  ...   3\n",
              " 2305         Sports  ...   0\n",
              " 5763  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 1534         Sports  ...   0\n",
              " 2831       Business  ...   1\n",
              " 4259     Technology  ...   2\n",
              " 4364     Technology  ...   2\n",
              " 1156         Sports  ...   0\n",
              " 3772       Business  ...   1\n",
              " 1956         Sports  ...   0\n",
              " 77           Sports  ...   0\n",
              " 5830  Entertainment  ...   3\n",
              " 5846  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 2394       Business  ...   1\n",
              " 2995       Business  ...   1\n",
              " 657          Sports  ...   0\n",
              " 581          Sports  ...   0\n",
              " 5776  Entertainment  ...   3\n",
              " 5861  Entertainment  ...   3\n",
              " 5867  Entertainment  ...   3\n",
              " 5878  Entertainment  ...   3\n",
              " 5168     Technology  ...   2\n",
              " 2459       Business  ...   1\n",
              " \n",
              " [10 rows x 7 columns],         Category  ... cat\n",
              " 3649    Business  ...   1\n",
              " 1410      Sports  ...   0\n",
              " 5464  Technology  ...   2\n",
              " 3299    Business  ...   1\n",
              " 4450  Technology  ...   2\n",
              " 4583  Technology  ...   2\n",
              " 4376  Technology  ...   2\n",
              " 3394    Business  ...   1\n",
              " 5057  Technology  ...   2\n",
              " 5326  Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 2988       Business  ...   1\n",
              " 375          Sports  ...   0\n",
              " 3947       Business  ...   1\n",
              " 1455         Sports  ...   0\n",
              " 5750  Entertainment  ...   3\n",
              " 5751  Entertainment  ...   3\n",
              " 73           Sports  ...   0\n",
              " 69           Sports  ...   0\n",
              " 5856  Entertainment  ...   3\n",
              " 5848  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 4116     Technology  ...   2\n",
              " 4429     Technology  ...   2\n",
              " 3115       Business  ...   1\n",
              " 3101       Business  ...   1\n",
              " 561          Sports  ...   0\n",
              " 548          Sports  ...   0\n",
              " 4052       Business  ...   1\n",
              " 3341       Business  ...   1\n",
              " 5785  Entertainment  ...   3\n",
              " 5909  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5689  Entertainment  ...   3\n",
              " 5878  Entertainment  ...   3\n",
              " 5878  Entertainment  ...   3\n",
              " 5790  Entertainment  ...   3\n",
              " 3307       Business  ...   1\n",
              " 3246       Business  ...   1\n",
              " 3090       Business  ...   1\n",
              " 4779     Technology  ...   2\n",
              " 4406     Technology  ...   2\n",
              " 4454     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5793  Entertainment  ...   3\n",
              " 5790  Entertainment  ...   3\n",
              " 1488         Sports  ...   0\n",
              " 1656         Sports  ...   0\n",
              " 3396       Business  ...   1\n",
              " 2743       Business  ...   1\n",
              " 5843  Entertainment  ...   3\n",
              " 5878  Entertainment  ...   3\n",
              " 5058     Technology  ...   2\n",
              " 4631     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 2350         Sports  ...   0\n",
              " 38           Sports  ...   0\n",
              " 4219     Technology  ...   2\n",
              " 5894  Entertainment  ...   3\n",
              " 2756       Business  ...   1\n",
              " 2999       Business  ...   1\n",
              " 5409     Technology  ...   2\n",
              " 4637     Technology  ...   2\n",
              " 3844       Business  ...   1\n",
              " 3511       Business  ...   1\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5795  Entertainment  ...   3\n",
              " 5798  Entertainment  ...   3\n",
              " 5867  Entertainment  ...   3\n",
              " 5852  Entertainment  ...   3\n",
              " 224          Sports  ...   0\n",
              " 5728  Entertainment  ...   3\n",
              " 5733  Entertainment  ...   3\n",
              " 5735  Entertainment  ...   3\n",
              " 4288     Technology  ...   2\n",
              " 5661     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5340     Technology  ...   2\n",
              " 782          Sports  ...   0\n",
              " 3852       Business  ...   1\n",
              " 4071       Business  ...   1\n",
              " 3521       Business  ...   1\n",
              " 3041       Business  ...   1\n",
              " 5811  Entertainment  ...   3\n",
              " 5839  Entertainment  ...   3\n",
              " 4376     Technology  ...   2\n",
              " 2837       Business  ...   1\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 3129       Business  ...   1\n",
              " 2788       Business  ...   1\n",
              " 4864     Technology  ...   2\n",
              " 5660     Technology  ...   2\n",
              " 4171     Technology  ...   2\n",
              " 4759     Technology  ...   2\n",
              " 2169         Sports  ...   0\n",
              " 3529       Business  ...   1\n",
              " 2380       Business  ...   1\n",
              " 5710  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5713  Entertainment  ...   3\n",
              " 5763  Entertainment  ...   3\n",
              " 152          Sports  ...   0\n",
              " 3026       Business  ...   1\n",
              " 3873       Business  ...   1\n",
              " 2452       Business  ...   1\n",
              " 5878  Entertainment  ...   3\n",
              " 5743  Entertainment  ...   3\n",
              " 1040         Sports  ...   0\n",
              " 1102         Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5216     Technology  ...   2\n",
              " 5210     Technology  ...   2\n",
              " 5041     Technology  ...   2\n",
              " 4125     Technology  ...   2\n",
              " 4230     Technology  ...   2\n",
              " 4815     Technology  ...   2\n",
              " 5818  Entertainment  ...   3\n",
              " 5867  Entertainment  ...   3\n",
              " 2131         Sports  ...   0\n",
              " 5803  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],       Category  ... cat\n",
              " 997     Sports  ...   0\n",
              " 814     Sports  ...   0\n",
              " 1953    Sports  ...   0\n",
              " 1795    Sports  ...   0\n",
              " 581     Sports  ...   0\n",
              " 2957  Business  ...   1\n",
              " 2280    Sports  ...   0\n",
              " 2366    Sports  ...   0\n",
              " 256     Sports  ...   0\n",
              " 113     Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 4108     Technology  ...   2\n",
              " 2455       Business  ...   1\n",
              " 4173     Technology  ...   2\n",
              " 4431     Technology  ...   2\n",
              " 5496     Technology  ...   2\n",
              " 5545     Technology  ...   2\n",
              " 5745  Entertainment  ...   3\n",
              " 5741  Entertainment  ...   3\n",
              " 4865     Technology  ...   2\n",
              " 3749       Business  ...   1\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 32           Sports  ...   0\n",
              " 750          Sports  ...   0\n",
              " 5552     Technology  ...   2\n",
              " 5542     Technology  ...   2\n",
              " 5874  Entertainment  ...   3\n",
              " 67           Sports  ...   0\n",
              " 1168         Sports  ...   0\n",
              " 1702         Sports  ...   0\n",
              " 1503         Sports  ...   0\n",
              " 5135     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 336          Sports  ...   0\n",
              " 334          Sports  ...   0\n",
              " 2113         Sports  ...   0\n",
              " 82           Sports  ...   0\n",
              " 4219     Technology  ...   2\n",
              " 5830  Entertainment  ...   3\n",
              " 5712  Entertainment  ...   3\n",
              " 5417     Technology  ...   2\n",
              " 4294     Technology  ...   2\n",
              " 4991     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 3129       Business  ...   1\n",
              " 2788       Business  ...   1\n",
              " 3248       Business  ...   1\n",
              " 555          Sports  ...   0\n",
              " 5745  Entertainment  ...   3\n",
              " 5741  Entertainment  ...   3\n",
              " 4035       Business  ...   1\n",
              " 1388         Sports  ...   0\n",
              " 5848  Entertainment  ...   3\n",
              " 5742  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 4610     Technology  ...   2\n",
              " 197          Sports  ...   0\n",
              " 1317         Sports  ...   0\n",
              " 1325         Sports  ...   0\n",
              " 713          Sports  ...   0\n",
              " 5878  Entertainment  ...   3\n",
              " 1304         Sports  ...   0\n",
              " 139          Sports  ...   0\n",
              " 5843  Entertainment  ...   3\n",
              " 5823  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 1957         Sports  ...   0\n",
              " 1918         Sports  ...   0\n",
              " 2603       Business  ...   1\n",
              " 5852  Entertainment  ...   3\n",
              " 929          Sports  ...   0\n",
              " 1473         Sports  ...   0\n",
              " 5441     Technology  ...   2\n",
              " 4611     Technology  ...   2\n",
              " 3475       Business  ...   1\n",
              " 3515       Business  ...   1\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5834  Entertainment  ...   3\n",
              " 5709  Entertainment  ...   3\n",
              " 5268     Technology  ...   2\n",
              " 4276     Technology  ...   2\n",
              " 2425       Business  ...   1\n",
              " 2562       Business  ...   1\n",
              " 4842     Technology  ...   2\n",
              " 5811  Entertainment  ...   3\n",
              " 5824  Entertainment  ...   3\n",
              " 5839  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 1282         Sports  ...   0\n",
              " 1306         Sports  ...   0\n",
              " 3483       Business  ...   1\n",
              " 2877       Business  ...   1\n",
              " 1054         Sports  ...   0\n",
              " 5775  Entertainment  ...   3\n",
              " 4872     Technology  ...   2\n",
              " 631          Sports  ...   0\n",
              " 4890     Technology  ...   2\n",
              " 4165     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 1306         Sports  ...   0\n",
              " 811          Sports  ...   0\n",
              " 5810  Entertainment  ...   3\n",
              " 5839  Entertainment  ...   3\n",
              " 3984       Business  ...   1\n",
              " 3969       Business  ...   1\n",
              " 544          Sports  ...   0\n",
              " 535          Sports  ...   0\n",
              " 5848  Entertainment  ...   3\n",
              " 5850  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5898  Entertainment  ...   3\n",
              " 4863     Technology  ...   2\n",
              " 4601     Technology  ...   2\n",
              " 5619     Technology  ...   2\n",
              " 594          Sports  ...   0\n",
              " 646          Sports  ...   0\n",
              " 4233     Technology  ...   2\n",
              " 4292     Technology  ...   2\n",
              " 972          Sports  ...   0\n",
              " 1167         Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 4284     Technology  ...   2\n",
              " 4756     Technology  ...   2\n",
              " 5914  Entertainment  ...   3\n",
              " 5919  Entertainment  ...   3\n",
              " 4576     Technology  ...   2\n",
              " 4910     Technology  ...   2\n",
              " 4753     Technology  ...   2\n",
              " 5533     Technology  ...   2\n",
              " 3491       Business  ...   1\n",
              " 3381       Business  ...   1\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5745  Entertainment  ...   3\n",
              " 5741  Entertainment  ...   3\n",
              " 1523         Sports  ...   0\n",
              " 1524         Sports  ...   0\n",
              " 5714  Entertainment  ...   3\n",
              " 299          Sports  ...   0\n",
              " 3378       Business  ...   1\n",
              " 5830  Entertainment  ...   3\n",
              " 5288     Technology  ...   2\n",
              " 245          Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5757  Entertainment  ...   3\n",
              " 5759  Entertainment  ...   3\n",
              " 1569         Sports  ...   0\n",
              " 2531       Business  ...   1\n",
              " 5232     Technology  ...   2\n",
              " 3767       Business  ...   1\n",
              " 4848     Technology  ...   2\n",
              " 1699         Sports  ...   0\n",
              " 468          Sports  ...   0\n",
              " 454          Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 2961       Business  ...   1\n",
              " 3749       Business  ...   1\n",
              " 5840  Entertainment  ...   3\n",
              " 5837  Entertainment  ...   3\n",
              " 5834  Entertainment  ...   3\n",
              " 2131         Sports  ...   0\n",
              " 2730       Business  ...   1\n",
              " 1206         Sports  ...   0\n",
              " 1656         Sports  ...   0\n",
              " 4987     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 3722       Business  ...   1\n",
              " 3596       Business  ...   1\n",
              " 5860  Entertainment  ...   3\n",
              " 5878  Entertainment  ...   3\n",
              " 4860     Technology  ...   2\n",
              " 4340     Technology  ...   2\n",
              " 1369         Sports  ...   0\n",
              " 1367         Sports  ...   0\n",
              " 5739  Entertainment  ...   3\n",
              " 773          Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 32           Sports  ...   0\n",
              " 750          Sports  ...   0\n",
              " 2904       Business  ...   1\n",
              " 3937       Business  ...   1\n",
              " 2545       Business  ...   1\n",
              " 3364       Business  ...   1\n",
              " 3707       Business  ...   1\n",
              " 3836       Business  ...   1\n",
              " 5912  Entertainment  ...   3\n",
              " 5910  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 1146         Sports  ...   0\n",
              " 1195         Sports  ...   0\n",
              " 5497     Technology  ...   2\n",
              " 5475     Technology  ...   2\n",
              " 952          Sports  ...   0\n",
              " 4159     Technology  ...   2\n",
              " 3853       Business  ...   1\n",
              " 5333     Technology  ...   2\n",
              " 5757  Entertainment  ...   3\n",
              " 5759  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 1978         Sports  ...   0\n",
              " 5131     Technology  ...   2\n",
              " 5867  Entertainment  ...   3\n",
              " 5878  Entertainment  ...   3\n",
              " 2350         Sports  ...   0\n",
              " 38           Sports  ...   0\n",
              " 5288     Technology  ...   2\n",
              " 1453         Sports  ...   0\n",
              " 5745  Entertainment  ...   3\n",
              " 5741  Entertainment  ...   3\n",
              " \n",
              " [10 rows x 7 columns],         Category  ... cat\n",
              " 3204    Business  ...   1\n",
              " 3221    Business  ...   1\n",
              " 4499  Technology  ...   2\n",
              " 4724  Technology  ...   2\n",
              " 3339    Business  ...   1\n",
              " 3765    Business  ...   1\n",
              " 3643    Business  ...   1\n",
              " 2420    Business  ...   1\n",
              " 2448    Business  ...   1\n",
              " 2420    Business  ...   1\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 1266         Sports  ...   0\n",
              " 3291       Business  ...   1\n",
              " 3584       Business  ...   1\n",
              " 3583       Business  ...   1\n",
              " 4268     Technology  ...   2\n",
              " 4317     Technology  ...   2\n",
              " 5851  Entertainment  ...   3\n",
              " 5846  Entertainment  ...   3\n",
              " 3852       Business  ...   1\n",
              " 165          Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5772  Entertainment  ...   3\n",
              " 5900  Entertainment  ...   3\n",
              " 5867  Entertainment  ...   3\n",
              " 5878  Entertainment  ...   3\n",
              " 5268     Technology  ...   2\n",
              " 1143         Sports  ...   0\n",
              " 5870  Entertainment  ...   3\n",
              " 5727  Entertainment  ...   3\n",
              " 873          Sports  ...   0\n",
              " 805          Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 3432       Business  ...   1\n",
              " 4181     Technology  ...   2\n",
              " 5781  Entertainment  ...   3\n",
              " 5775  Entertainment  ...   3\n",
              " 4136     Technology  ...   2\n",
              " 4804     Technology  ...   2\n",
              " 5897  Entertainment  ...   3\n",
              " 5890  Entertainment  ...   3\n",
              " 5417     Technology  ...   2\n",
              " 1446         Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 3032       Business  ...   1\n",
              " 3479       Business  ...   1\n",
              " 325          Sports  ...   0\n",
              " 3958       Business  ...   1\n",
              " 58           Sports  ...   0\n",
              " 5686  Entertainment  ...   3\n",
              " 5747  Entertainment  ...   3\n",
              " 5830  Entertainment  ...   3\n",
              " 640          Sports  ...   0\n",
              " 5497     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5825  Entertainment  ...   3\n",
              " 5853  Entertainment  ...   3\n",
              " 5181     Technology  ...   2\n",
              " 5839  Entertainment  ...   3\n",
              " 2129         Sports  ...   0\n",
              " 5710  Entertainment  ...   3\n",
              " 5818  Entertainment  ...   3\n",
              " 5867  Entertainment  ...   3\n",
              " 1873         Sports  ...   0\n",
              " 1355         Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5848  Entertainment  ...   3\n",
              " 5850  Entertainment  ...   3\n",
              " 4465     Technology  ...   2\n",
              " 4307     Technology  ...   2\n",
              " 802          Sports  ...   0\n",
              " 1052         Sports  ...   0\n",
              " 3776       Business  ...   1\n",
              " 574          Sports  ...   0\n",
              " 5413     Technology  ...   2\n",
              " 4471     Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5708  Entertainment  ...   3\n",
              " 5710  Entertainment  ...   3\n",
              " 1964         Sports  ...   0\n",
              " 38           Sports  ...   0\n",
              " 4321     Technology  ...   2\n",
              " 2343         Sports  ...   0\n",
              " 1338         Sports  ...   0\n",
              " 5060     Technology  ...   2\n",
              " 3706       Business  ...   1\n",
              " 3572       Business  ...   1\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 3906       Business  ...   1\n",
              " 5830  Entertainment  ...   3\n",
              " 3841       Business  ...   1\n",
              " 4570     Technology  ...   2\n",
              " 4577     Technology  ...   2\n",
              " 5739  Entertainment  ...   3\n",
              " 5882  Entertainment  ...   3\n",
              " 5292     Technology  ...   2\n",
              " 2713       Business  ...   1\n",
              " 372          Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns],         Category  ... cat\n",
              " 704       Sports  ...   0\n",
              " 738       Sports  ...   0\n",
              " 2688    Business  ...   1\n",
              " 3667    Business  ...   1\n",
              " 2852    Business  ...   1\n",
              " 1021      Sports  ...   0\n",
              " 5292  Technology  ...   2\n",
              " 4628  Technology  ...   2\n",
              " 3164    Business  ...   1\n",
              " 4391  Technology  ...   2\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 4337     Technology  ...   2\n",
              " 2513       Business  ...   1\n",
              " 5897  Entertainment  ...   3\n",
              " 5890  Entertainment  ...   3\n",
              " 779          Sports  ...   0\n",
              " 812          Sports  ...   0\n",
              " 5757  Entertainment  ...   3\n",
              " 5759  Entertainment  ...   3\n",
              " 3920       Business  ...   1\n",
              " 3955       Business  ...   1\n",
              " \n",
              " [10 rows x 7 columns],            Category  ... cat\n",
              " 5801  Entertainment  ...   3\n",
              " 5775  Entertainment  ...   3\n",
              " 139          Sports  ...   0\n",
              " 155          Sports  ...   0\n",
              " 2157         Sports  ...   0\n",
              " 3749       Business  ...   1\n",
              " 2404       Business  ...   1\n",
              " 3356       Business  ...   1\n",
              " 1531         Sports  ...   0\n",
              " 1615         Sports  ...   0\n",
              " \n",
              " [10 rows x 7 columns]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJSLyA_Yswzd"
      },
      "source": [
        "So hear we have recommandations for every user on the server Have a Good Day..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxjET8AktHXM"
      },
      "source": [
        "#Summery\n",
        "We have used two powerful algorithms to devlop our recommandation system NER+LSH\n",
        "\n",
        "As we can see the results we are getting better recommandations by using these two algorithms even these model is preety fast and handy to use even for all the 100 users with 150000 data points this algorithm gives recommandations to each user in less then one min which is extreemly fast.. \n",
        "\n",
        "So even for the small servers we can use this recommandation system to save time and this model will work efficientely.\n",
        "\n",
        "only slow process in this algorithm is getting NER tags on normal CPU it will take too much time but hear we are using google collab GPUs so we are getting results within 10 min but once NER tagging is done everything is blezzing fast.\n",
        "\n",
        "For collabrative filturing we've sticked to our algorithm and decided not to use any other mathodes because mathamatically speaking every other mathod will take more computational time then this model and even if we are using K-nearest nabour mathod then we will definetly loose more data then this mathod even for metrix factorization we will make a model by using just stastictical data but in this mathod we are using news tags by using NER so we will not loose any details about users intrusts.\n",
        "\n",
        "Hope you will like our algorithm for Jhakkas Newswala. download this notebook and run into google collab and experience this amazing algorithm.\n",
        "\n",
        "Thankyou.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsGyi6ByqIUn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}